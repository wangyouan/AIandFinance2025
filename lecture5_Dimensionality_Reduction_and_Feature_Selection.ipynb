{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea02c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c89212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## use wrds package to connect to WRDS\n",
    "import wrds\n",
    "wrds_user = os.getenv(\"WRDS_USER\")\n",
    "db = wrds.Connection(wrds_username=wrds_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a781edc3",
   "metadata": {},
   "source": [
    "## 1. Principal Component Analysis (PCA)\n",
    "\n",
    "- **Basic Principles and Mathematical Formulation**\n",
    "  - Core ideas: finding the optimal hyperplane such that:\n",
    "    - **Minimum reconstruction error**: minimize the distance from sample points to the hyperplane\n",
    "    - **Maximum separability**: maximize the variance of the projected samples\n",
    "\n",
    "  - Algorithm steps:\n",
    "    1. **Data standardization**:  \n",
    "       $$\n",
    "       x_{ij}^* = \\frac{x_{ij} - \\bar{x}_j}{\\sqrt{\\text{Var}(x_j)}}\n",
    "       $$\n",
    "    2. **Compute the correlation matrix**:  \n",
    "       $$\n",
    "       R = \\frac{Z'Z}{n-1}, \\quad Z = \\text{standardized data matrix}\n",
    "       $$\n",
    "    3. **Eigen-decomposition**:  \n",
    "       $$\n",
    "       R = U\\Lambda U', \\quad \\Lambda = \\text{diag}(\\lambda_1,...,\\lambda_p)\n",
    "       $$\n",
    "    4. **Extract principal components**:  \n",
    "       $$\n",
    "       Y_i = Xu_i, \\quad u_i = \\text{eigenvector of the $i$-th largest eigenvalue}\n",
    "       $$\n",
    "\n",
    "- **Advantages and Limitations**\n",
    "\n",
    "| Advantages       | Explanation                              | Limitations      | Explanation                                  |\n",
    "|------------------|------------------------------------------|------------------|----------------------------------------------|\n",
    "| Data compression | Increases sample density and usability   | Poor interpretability | Principal components lack economic meaning |\n",
    "| Noise reduction  | Discarded components often correspond to noise | Linear assumption | Only captures linear relationships |\n",
    "| Ease of use      | Requires no complex parameter tuning     | Distribution-sensitive | Less effective under non-Gaussian distributions |\n",
    "\n",
    "- **Extensions**\n",
    "\n",
    "  - **Instrumented PCA (IPCA)**\n",
    "    - Proposed by: Kelly et al. (2021)\n",
    "    - Model form:\n",
    "      $$\n",
    "      r_{i,t+1} = a_{i,t} + \\beta_{i,t}f_{t+1} + \\epsilon_{i,t+1}\n",
    "      $$\n",
    "      $$\n",
    "      a_{i,t} = x'_{i,t}\\Gamma_a + v_{a,t}, \\quad \\beta_{i,t} = x'_{i,t}\\Gamma_\\beta + v_{\\beta,t}\n",
    "      $$\n",
    "    - Features:\n",
    "      - Introduces time-varying β to capture dynamic risk premia\n",
    "      - Distinguishes between systematic risk ($\\Gamma_\\beta$) and idiosyncratic risk ($\\Gamma_\\alpha$)\n",
    "\n",
    "  - **Scaled PCA (sPCA)**\n",
    "    - Huang, D., Jiang, F., Li, K., Tong, G., & Zhou, G. (2022). *Scaled PCA: A new approach to dimension reduction.* Management Science.\n",
    "      - Construct effective predictor set:  \n",
    "        $$\n",
    "        y_{t+h} = v_i + \\gamma_i X_{i,t} + u_{i,t+h}\n",
    "        $$\n",
    "      - Apply PCA to scaled predictors\n",
    "    - Higher-weight is given to information-rich variables\n",
    "    - Lower-weight is assigned to noisy variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f9a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a252a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vwretd</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>totval</th>\n",
       "      <th>totcnt</th>\n",
       "      <th>usdval</th>\n",
       "      <th>usdcnt</th>\n",
       "      <th>spindx</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caldt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-31</th>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>-0.004771</td>\n",
       "      <td>10202644100.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10177769000.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1104.24</td>\n",
       "      <td>0.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.009347</td>\n",
       "      <td>0.02757</td>\n",
       "      <td>0.026265</td>\n",
       "      <td>10285563700.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10200534100.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1114.58</td>\n",
       "      <td>0.009364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-29</th>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.024507</td>\n",
       "      <td>0.023589</td>\n",
       "      <td>10400365400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10253103200.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1130.2</td>\n",
       "      <td>0.014014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-30</th>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.035572</td>\n",
       "      <td>0.058717</td>\n",
       "      <td>0.05686</td>\n",
       "      <td>10775860400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10392258900.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1173.82</td>\n",
       "      <td>0.038595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.033734</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.037578</td>\n",
       "      <td>0.035933</td>\n",
       "      <td>11174847000.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10810662000.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1211.92</td>\n",
       "      <td>0.032458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-30</th>\n",
       "      <td>-0.029207</td>\n",
       "      <td>-0.031638</td>\n",
       "      <td>-0.027829</td>\n",
       "      <td>-0.029855</td>\n",
       "      <td>14967939700.0</td>\n",
       "      <td>500</td>\n",
       "      <td>15481333300.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1632.97</td>\n",
       "      <td>-0.031298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>0.03166</td>\n",
       "      <td>0.030064</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>15425476800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>14998800000.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1681.55</td>\n",
       "      <td>0.02975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-31</th>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.044953</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>16084261800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>15417335700.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1756.54</td>\n",
       "      <td>0.044596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-29</th>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.028398</td>\n",
       "      <td>0.023739</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>16530422500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>16089180200.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1805.81</td>\n",
       "      <td>0.02805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>0.02595</td>\n",
       "      <td>0.024196</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.02771</td>\n",
       "      <td>17040676100.0</td>\n",
       "      <td>500</td>\n",
       "      <td>16648053400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1848.36</td>\n",
       "      <td>0.023563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              vwretd    vwretx    ewretd    ewretx         totval  totcnt  \\\n",
       "caldt                                                                       \n",
       "2004-08-31  0.003807  0.002019 -0.002948 -0.004771  10202644100.0     500   \n",
       "2004-09-30  0.010817  0.009347   0.02757  0.026265  10285563700.0     500   \n",
       "2004-10-29  0.014973  0.013699  0.024507  0.023589  10400365400.0     500   \n",
       "2004-11-30  0.040559  0.035572  0.058717   0.05686  10775860400.0     500   \n",
       "2004-12-31  0.033734  0.032086  0.037578  0.035933  11174847000.0     500   \n",
       "...              ...       ...       ...       ...            ...     ...   \n",
       "2013-08-30 -0.029207 -0.031638 -0.027829 -0.029855  14967939700.0     500   \n",
       "2013-09-30   0.03166  0.030064  0.040402  0.038552  15425476800.0     500   \n",
       "2013-10-31  0.046268  0.044953  0.042828  0.041839  16084261800.0     500   \n",
       "2013-11-29  0.030817  0.028398  0.023739  0.021743  16530422500.0     500   \n",
       "2013-12-31   0.02595  0.024196  0.029739   0.02771  17040676100.0     500   \n",
       "\n",
       "                   usdval  usdcnt   spindx    sprtrn  \n",
       "caldt                                                 \n",
       "2004-08-31  10177769000.0     500  1104.24  0.002287  \n",
       "2004-09-30  10200534100.0     500  1114.58  0.009364  \n",
       "2004-10-29  10253103200.0     500   1130.2  0.014014  \n",
       "2004-11-30  10392258900.0     500  1173.82  0.038595  \n",
       "2004-12-31  10810662000.0     500  1211.92  0.032458  \n",
       "...                   ...     ...      ...       ...  \n",
       "2013-08-30  15481333300.0     500  1632.97 -0.031298  \n",
       "2013-09-30  14998800000.0     500  1681.55   0.02975  \n",
       "2013-10-31  15417335700.0     500  1756.54  0.044596  \n",
       "2013-11-29  16089180200.0     500  1805.81   0.02805  \n",
       "2013-12-31  16648053400.0     500  1848.36  0.023563  \n",
       "\n",
       "[113 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Obtain S&P500 data\n",
    "sp500_df = db.raw_sql(\"\"\"select * \n",
    "                        from crsp_a_indexes.msp500\n",
    "                        where \n",
    "                        caldt >= '08/01/2004' and             \n",
    "                        caldt <= '12/31/2013'\n",
    "                    \"\"\", date_cols=['caldt'])    #  02/01/2005 & 12/31/2013 11/01/2004 & 12/31/2013  08/01/2004 & 12/31/2013\n",
    "\n",
    "sp500_df.set_index([\"caldt\"], drop=True, inplace=True)\n",
    "sp500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d397d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D12</th>\n",
       "      <th>E12</th>\n",
       "      <th>b/m</th>\n",
       "      <th>tbl</th>\n",
       "      <th>AAA</th>\n",
       "      <th>BAA</th>\n",
       "      <th>lty</th>\n",
       "      <th>ntis</th>\n",
       "      <th>infl</th>\n",
       "      <th>ltr</th>\n",
       "      <th>svar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-07-01</th>\n",
       "      <td>18.7890</td>\n",
       "      <td>56.6900</td>\n",
       "      <td>0.287788</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-01</th>\n",
       "      <td>18.9760</td>\n",
       "      <td>57.2300</td>\n",
       "      <td>0.286821</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-09-01</th>\n",
       "      <td>19.1630</td>\n",
       "      <td>57.7700</td>\n",
       "      <td>0.289485</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-10-01</th>\n",
       "      <td>19.2560</td>\n",
       "      <td>58.0300</td>\n",
       "      <td>0.291010</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-11-01</th>\n",
       "      <td>19.3490</td>\n",
       "      <td>58.2900</td>\n",
       "      <td>0.279832</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>33.6455</td>\n",
       "      <td>92.0900</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-0.0173</td>\n",
       "      <td>0.000502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>34.0247</td>\n",
       "      <td>93.2300</td>\n",
       "      <td>0.340713</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-01</th>\n",
       "      <td>34.4039</td>\n",
       "      <td>94.3700</td>\n",
       "      <td>0.333521</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>34.6000</td>\n",
       "      <td>96.3133</td>\n",
       "      <td>0.324595</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01</th>\n",
       "      <td>34.7960</td>\n",
       "      <td>98.2567</td>\n",
       "      <td>0.313685</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                D12      E12       b/m     tbl     AAA     BAA     lty  \\\n",
       "Dates                                                                    \n",
       "2004-07-01  18.7890  56.6900  0.287788  0.0133  0.0582  0.0662  0.0523   \n",
       "2004-08-01  18.9760  57.2300  0.286821  0.0148  0.0565  0.0646  0.0493   \n",
       "2004-09-01  19.1630  57.7700  0.289485  0.0165  0.0546  0.0627  0.0488   \n",
       "2004-10-01  19.2560  58.0300  0.291010  0.0176  0.0547  0.0621  0.0478   \n",
       "2004-11-01  19.3490  58.2900  0.279832  0.0207  0.0552  0.0620  0.0502   \n",
       "...             ...      ...       ...     ...     ...     ...     ...   \n",
       "2013-07-01  33.6455  92.0900  0.325563  0.0004  0.0434  0.0532  0.0344   \n",
       "2013-08-01  34.0247  93.2300  0.340713  0.0004  0.0454  0.0542  0.0351   \n",
       "2013-09-01  34.4039  94.3700  0.333521  0.0002  0.0464  0.0547  0.0349   \n",
       "2013-10-01  34.6000  96.3133  0.324595  0.0005  0.0453  0.0531  0.0342   \n",
       "2013-11-01  34.7960  98.2567  0.313685  0.0007  0.0463  0.0538  0.0361   \n",
       "\n",
       "                ntis      infl     ltr      svar  \n",
       "Dates                                             \n",
       "2004-07-01  0.014721 -0.001581  0.0155  0.000777  \n",
       "2004-08-01  0.014279  0.000528  0.0395  0.001443  \n",
       "2004-09-01  0.009132  0.002111  0.0096  0.000706  \n",
       "2004-10-01  0.007429  0.005266  0.0154  0.001230  \n",
       "2004-11-01  0.012177  0.000524 -0.0234  0.000857  \n",
       "...              ...       ...     ...       ...  \n",
       "2013-07-01  0.008361  0.000394 -0.0173  0.000502  \n",
       "2013-08-01  0.010332  0.001203 -0.0079  0.000950  \n",
       "2013-09-01  0.010119  0.001163  0.0061  0.000622  \n",
       "2013-10-01  0.009623 -0.002575  0.0128  0.001438  \n",
       "2013-11-01  0.010325 -0.002042 -0.0236  0.000644  \n",
       "\n",
       "[113 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macroeconomic predictors (from Amit Goyal homepage)\n",
    "# Variables:\n",
    "#   D12: Dividends are 12-month moving sums of dividends paid on the S&P 500 index.\n",
    "#   E12: Earnings are 12-month moving sums of earnings on the S&P500 index.\n",
    "#   B/M: Book-to-market ratio\n",
    "#   TBL: T-Bill rates (U.S. Yields On Short-Term United States Securities,)\n",
    "#   AAA(BAA): Corporate Bond Yields on AAA(BAA)-related bonds\n",
    "#   Lty: long-term government bond yield\n",
    "#   Ntis: Net issuing activity.\n",
    "#   infl: inflation\n",
    "#   SVAR: Stock Variance is computed as sum of squared daily returns on the S&P 500.\n",
    "predictors = pd.read_csv(os.path.join('data', 'l5', \"PredictorData2024.csv\"), index_col=0).iloc[:-2,:]\n",
    "predictors.loc[:,'Dates'] = predictors.index.astype(int).astype(str).values\n",
    "predictors.set_index(pd.to_datetime(predictors.loc[:,'Dates'], format=\"%Y%m\"), inplace = True)\n",
    "X = predictors.loc[\"2004-07-01\":\"2013-11-01\", ['D12','E12','b/m','tbl','AAA','BAA','lty','ntis','infl','ltr','svar']].copy(deep=True)\n",
    "y = sp500_df.loc[:,'sprtrn'].values - predictors.loc[\"2004-08-01\":\"2013-12-01\",'Rfree'].values\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcb5a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm(in_df, no_Norm=[]):\n",
    "    op_df = in_df.copy()\n",
    "    for col in op_df.columns:\n",
    "        if col in no_Norm:\n",
    "            continue\n",
    "        else:\n",
    "            col_max = max(op_df[col])\n",
    "            col_min = min(op_df[col])\n",
    "            if col_max == col_min:\n",
    "                continue\n",
    "            op_df[col] = (op_df[col] - col_min) / (col_max - col_min)\n",
    "    return op_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e29c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA analysis\n",
    "X_normed = Norm(X)\n",
    "n = 6\n",
    "pca = PCA(n_components=n)\n",
    "X_pca = pca.fit_transform(X_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96369de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PCA Visualization\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Explained Variance Ratio\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), 'o-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "plt.title('PCA Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa329ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PCA Loading Matrix')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAIOCAYAAAAfuXO/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPZRJREFUeJzt3X18jfXjx/H3sdkZM7NkNvR1m/u5SwyVu5RIEilyT4XSzUItaeaL4fuNSsVXmOZmKPQt5Rcxd7ntZ0SUYlhuUszNyGm26/dHP/s537k55+w6rp9zXs/H4zwe23V9ruu8z67v9N7ne53PsRmGYQgAAACAZQpZHQAAAADwd5RyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBilHIAt5zZs2fLZrPlPQIDA1WuXDn17dtXR44cyTf+wIEDev7551W1alUVKVJERYsWVa1atfTGG29cdbwkPfbYY7LZbHr++efdyubJMd7SokULtWjRIu/7gwcPymazafbs2Tc9y+XnttlsGjVq1FXH9OvXL2+MJ7788strnvt6rpcJAG4WSjmAW1ZSUpI2bdqklStX6umnn1ZKSoruvfdenT9/Pm/MsmXLVKdOHS1btkzPPPOMli1blvf1559/rocffjjfeU+cOKFly5ZJkubNm6eLFy/etNfkTVFRUdq0aZPat29vWYbQ0FDNnj1bubm5TtuzsrL08ccfq3jx4h6f+8svv1RCQoLbx23atEkDBgzw+HkBwAyUcgC3rNq1aysmJkYtW7ZUfHy8hg8frvT0dH366aeSpPT0dD355JOqWrWqdu7cqaFDh6p169Zq1aqVXnzxRe3YsUMjR47Md97k5GRlZ2erffv2On36tJYsWXKTX5l32O12xcTEqFSpUpZleOKJJ3To0CGtWrXKafvChQuVk5OjRx555KbkMAxDf/zxhyQpJiZG5cqVuynPCwDXQikH4DNiYmIkSYcOHZIkTZo0SefPn9cHH3ygsLCwfONtNpsee+yxfNtnzZql0qVL66OPPlKRIkU0a9YsU3OeOnVKgwcPVtmyZRUUFKRKlSppxIgRcjgcTuPef/993XfffYqIiFBISIiio6M1ceJEZWdnO40zDEMTJ05U+fLlFRwcrAYNGmj58uX5nvdqt6+MGjVKNptN33//vbp166awsDCVLl1a/fr105kzZ5yOP336tPr376/bbrtNxYoVU/v27XXgwAG3bv+oVq2amjZtmu9nOmvWLD322GNXvU4LFy7UAw88oKioKBUpUkQ1atTQa6+95vT/iPTp00fvv/++JDnd2nTw4MG8bc8//7ymTZumGjVqyG6366OPPsrbdzm/YRhq166dSpYsqcOHD+ed/8KFC6pVq5Zq1Kjh9LwAYJZAqwMAgFl+/vlnScqbCV6xYoVKly6dV9ZdsXHjRu3du1fDhg1TyZIl1blzZ82bN0/p6emqWLFigTNevHhRLVu21P79+5WQkKA6depo/fr1SkxM1I4dO/TFF1/kjd2/f7+6d++uihUrKigoSDt37tTYsWP1ww8/OJXahIQEJSQkqH///urSpYsyMjL09NNPKycnR9WqVXMpV+fOnfXEE0+of//+2rVrl+Li4iQp73lyc3PVoUMHffvttxo1apQaNGigTZs2qW3btm7/DPr376/nnntOmZmZCg8P148//qiNGzdqzJgxWrx4cb7xP/30k9q1a6eXXnpJISEh+uGHHzRhwgRt3bpVq1evliSNHDlS58+f1yeffKJNmzblHRsVFZX39aeffqr169frzTffVGRkpCIiIvI9l81m05w5c1SvXj117dpV69evV+HChTV48GClp6dry5YtCgkJcfs1A8ANGQBwi0lKSjIkGZs3bzays7ONc+fOGcuWLTNKlSplhIaGGsePHzcMwzCCg4ONmJgYt87dr18/Q5Kxd+9ewzAMIzU11ZBkjBw50qXjJRnPPffcNfdPmzbNkGQsWrTIafuECRMMScaKFSuuelxOTo6RnZ1tJCcnGwEBAcapU6cMwzCMzMxMIzg42OjUqZPT+G+++caQZDRv3jxvW3p6uiHJSEpKytsWHx9vSDImTpzodPzgwYON4OBgIzc31zAMw/jiiy8MScbUqVOdxiUmJhqSjPj4+Gu+5iuf+x//+Idx7tw5o1ixYsZ7771nGIZhDBs2zKhYsaKRm5trPPfcc8b1/tOUm5trZGdnG2vXrjUkGTt37szbd71jJRlhYWF5P7f/3Pef+Tds2GAEBgYaL730kjFr1ixDkjFjxozrvkYAKAhuXwFwy4qJiVHhwoUVGhqqhx9+WJGRkVq+fLlKly7t0fmysrK0aNEiNW3aVNWrV5ckNW/eXJUrV77qmxM9sXr1aoWEhKhLly5O2/v06SNJTvdap6Wl6ZFHHlHJkiUVEBCgwoULq1evXsrJydG+ffsk/fUmxYsXL+qpp55yOl/Tpk1Vvnx5l3P9573cderU0cWLF3XixAlJ0tq1ayVJXbt2dRrXrVs3l5/jsmLFiunxxx/XrFmzdOnSJSUnJ6tv377XXHXlwIED6t69uyIjI/N+Ds2bN5ck7d271+XnbdWqlcLDw10a26xZM40dO1Zvv/22Bg0apB49eqh///4uPxcAuItSDuCWlZycrG3btiktLU1Hjx7Vd999p2bNmuXt/9vf/qb09HSXz7dw4UJlZWWpa9euOn36tE6fPq0zZ86oa9euysjI0MqVKwuc+eTJk4qMjMxXQCMiIhQYGKiTJ09Kkg4fPqx7771XR44c0TvvvKP169dr27ZtefdNX36T4uXxkZGR+Z7ratuupWTJkk7f2+32fM8TGBio2267zWmcp38A9e/fX9u3b9fYsWP122+/5f1R8p+ysrJ07733asuWLRozZozWrFmjbdu25b359nI+V1x5K4srnnrqKQUFBcnhcGjYsGFuHQsA7uKecgC3rBo1aqhhw4bX3P/ggw9qypQp2rx5s0v3lc+cOVOS9NJLL+mll1666v4HH3zQ47zSX+V3y5YtMgzDqZifOHFCly5d0u233y7pr/ufz58/ryVLljjNeO/YsSPf+STp+PHj+Z7r+PHjqlChQoHyXvk8ly5d0qlTp5yK+dWe1xXNmjVTtWrVNHr0aLVp00Z33HHHVcetXr1aR48e1Zo1a/Jmx6W/3nTqLnfWP8/JydFTTz2l8PBw2e129e/fX998842CgoLcfl4AcAUz5QB81ssvv6yQkBANHjw430oi0l8rbSxdulTSX7dBbNq0SZ07d1Zqamq+R+vWrfXvf/87b2baU61bt1ZWVlbeso2XJScn5+2X/q9AXp6xvpz3ww8/dDouJiZGwcHBmjdvntP2jRs35q1CY4bLhXjhwoVO2xcsWODxOd944w116NBBr7zyyjXHXO3nIEn/+te/8o39z9n9goiPj9f69es1b948LVy4UDt37mS2HIBXMVMOwGdVrFhRCxYs0BNPPKF69erp+eefV/369SVJe/bs0axZs2QYhjp16pQ3Sz58+HA1atQo37nOnTunVatWae7cuXrxxRev+7z79+/XJ598km97zZo11atXL73//vvq3bu3Dh48qOjoaG3YsEHjxo1Tu3btdP/990uS2rRpo6CgIHXr1k3Dhw/XxYsXNXXqVGVmZjqdMzw8XEOHDtWYMWM0YMAAPf7448rIyNCoUaPcun3lRtq2batmzZrplVde0dmzZ3XXXXdp06ZNeX9MFCrk/hxPjx491KNHj+uOadq0qcLDwzVw4EDFx8ercOHCmjdvnnbu3JlvbHR0tCRpwoQJeuihhxQQEKA6deq4Pbu9cuVKJSYmauTIkXl/JCUmJmro0KFq0aKFOnXq5Nb5AMAl1r7PFADcd3n1lW3btrk0fv/+/cbgwYONKlWqGHa73ShSpIhRs2ZNIzY21khPTzf+/PNPIyIiwqhXr941z3Hp0iWjXLlyRnR09HWfS9I1H5dX+Dh58qQxcOBAIyoqyggMDDTKly9vxMXFGRcvXnQ61+eff27UrVvXCA4ONsqWLWsMGzbMWL58uSHJSE1NzRuXm5trJCYmGnfccYcRFBRk1KlTx/j888+N5s2bu7z6ym+//eb03Jd/xunp6XnbTp06ZfTt29coUaKEUbRoUaNNmzbG5s2bDUnGO++8c92fy5Wrr1zP1VZQ2bhxo9GkSROjaNGiRqlSpYwBAwYY27dvz/daHA6HMWDAAKNUqVKGzWZzyq/rrIpz5bU5evSoERERYbRq1crIycnJG5Obm2t06NDBKFGihNPPBADMYjMMw7jJfwcAAHzE/Pnz9dRTT+mbb75R06ZNrY4DALcsSjkAwCUpKSk6cuSIoqOjVahQIW3evFn/+Mc/VL9+/bwlEwEAnuGecgCAS0JDQ7VgwQKNGTNG58+fV1RUlPr06aMxY8ZYHQ0AbnnMlAMAAAAWY0lEAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBi/6+WREw7dM7qCDBB/fKhVkeAF1zIZqEmX1C0sE2SNGndAYuTwCyx91WSJG09cMbiJDBDo0phkqTWUzZZnARmWDWkictjmSkHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALOZWKc/Oztbw4cNVpUoVNWrUSElJSU77f/31VwUEBJgaEAAAAPB1bpXysWPHKjk5WQMHDtQDDzygl19+Wc8++6zTGMMwTA0IAAAA+LpAdwbPmzdPM2bM0MMPPyxJ6tu3rx566CH17dtXs2bNkiTZbDbzUwIAAAA+zK2Z8iNHjqh27dp531euXFlr1qzRpk2b1LNnT+Xk5JgeEAAAAPB1bpXyyMhI7d+/32lbmTJltHr1am3btk29e/c2NRwAAADgD9wq5a1atdL8+fPzbb9czA8ePGhWLgAAAMBvuHVP+ciRI/XDDz9cdV/ZsmW1bt06rVixwpRgAAAAgL9wq5SXL19e5cuXv+b+qKgobmEBAAAA3GTqhwdlZmYqOTn5huMcDofOnj3r9HA4HGZGAQAAAG4Zppbyw4cPq2/fvjccl5iYqLCwMKdHYmKimVEAAACAW4Zbt6+cPXv2uvvPnTvn0nni4uIUGxvrtM1ut2vP8T/diQMAAAD4BLdKeYkSJa774UCGYbj04UF2u112u/0qeyjlAAAA8D9ulfLQ0FCNGDFCjRs3vur+n376Sc8++6wpwQAAAAB/4VYpb9CggSSpefPmV91fokQJGYZR8FQAAACAH3HrjZ7du3dXcHDwNfdHRkYqPj6+wKEAAAAAf+LWTPnTTz993f2lS5emlAMAAABucquUS1Jubq5mz56tJUuW6ODBg7LZbKpYsaK6dOminj17uvRGTwAAAAD/x63bVwzDUIcOHTRgwAAdOXJE0dHRqlWrlg4dOqQ+ffqoU6dO3soJAAAA+Cy3Zspnz56t9evXa9WqVWrZsqXTvtWrV+vRRx9VcnKyevXqZWpIAAAAwJe5NVOekpKi119/PV8hl6RWrVrptdde07x580wLBwAAAPgDt0r5d999p7Zt215z/0MPPaSdO3cWOBQAAADgT9wq5adOnVLp0qWvub906dLKzMwscCgAAADAn7hVynNychQYeO3b0AMCAnTp0qUChwIAAAD8iVtv9DQMQ3369JHdbr/qfofDYUooAAAAwJ+4Vcp79+59wzGsvAIAAAC4x61SnpSU5K0cAAAAgN9y655yAAAAAOajlAMAAAAWo5QDAAAAFrMZhmFYHQIAAADwZ8yUAwAAABZza/UVb0v98aTVEWCCltVKSpIajkm1OAnM8O0bLSVJX+w+YXESmKF97QhJ/HvrSy7/m7v36HmLk8AMNcqESJLGrdpvcRKY4fXWlV0ey0w5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxt0p5dna2hg8fripVqqhRo0ZKSkpy2v/rr78qICDA1IAAAACAr3OrlI8dO1bJyckaOHCgHnjgAb388st69tlnncYYhmFqQAAAAMDXBbozeN68eZoxY4YefvhhSVLfvn310EMPqW/fvpo1a5YkyWazmZ8SAAAA8GFuzZQfOXJEtWvXzvu+cuXKWrNmjTZt2qSePXsqJyfH9IAAAACAr3OrlEdGRmr//v1O28qUKaPVq1dr27Zt6t27t6nhAAAAAH/gVilv1aqV5s+fn2/75WJ+8OBBs3IBAAAAfsOte8pHjhypH3744ar7ypYtq3Xr1mnFihWmBAMAAAD8hVulvHz58ipfvvw190dFRbl0C4vD4ZDD4XDaZrfb3YkCAAAA+AxTPzwoMzNTycnJNxyXmJiosLAwp0diYqKZUQAAAIBbhqml/PDhw+rbt+8Nx8XFxenMmTNOj7i4ODOjAAAAALcMt25fOXv27HX3nzt3zqXz2O32a9yukuVOHAAAAMAnuFXKS5Qocd0PBzIMgw8PAgAAANzkVikPDQ3ViBEj1Lhx46vu/+mnn/Tss8+aEgwAAADwF26V8gYNGkiSmjdvftX9JUqUkGEYBU8FAAAA+BG33ujZvXv36y5dGBkZqfj4+AKHAgAAAPyJWzPlTz/99HX3ly5dmlIOAAAAuMmtmfJ27drpzJkzed+PHTtWp0+fzvv+5MmTqlmzpmnhAAAAAH/gVin/r//6L6dP4pwwYYJOnTqV9/2lS5f0448/mpcOAAAA8AMF+vAg3tQJAAAAFJypn+gJAAAAwH1ulXKbzZbvw4H4sCAAAACgYNxafcUwDPXp0ydvWcSLFy9q4MCBCgkJkSSn+80BAAAAuMatUt67d2+n73v06JFvTK9evQqWCAAAAPAzbpXypKQkb+UAAAAA/BZv9AQAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsZjP4WE4AAADAUsyUAwAAABZza0lEb9v1S5bVEWCC6HLFJEk7M85ZnARmqHtHqCTphU9/sDgJzPDuo9Ul8fvpSy7/jnae9d8WJ4EZFve7S5LUesomi5PADKuGNHF5LDPlAAAAgMUo5QAAAIDFKOUAAACAxSjlAAAAgMUo5QAAAIDFKOUAAACAxSjlAAAAgMUo5QAAAIDFKOUAAACAxSjlAAAAgMUCPT3w4sWLmjJlilJTU3XixAnl5uY67d++fXuBwwEAAAD+wONS3q9fP61cuVJdunRRo0aNZLPZzMwFAAAA+A2PS/kXX3yhL7/8Us2aNTMzDwAAAOB3PL6nvGzZsgoNDTUzCwAAAOCXPC7lb731ll599VUdOnTIzDwAAACA3/H49pWGDRvq4sWLqlSpkooWLarChQs77T916lSBwwEAAAD+wONS3q1bNx05ckTjxo1T6dKleaMnAAAA4CGPS/nGjRu1adMm1a1b18w8AAAAgN/xuJRXr15df/zxh0fHOhwOORwOp212u93TKAAAAMAtzeM3eo4fP16vvPKK1qxZo5MnT+rs2bNOj+tJTExUWFiY0yMxMdHTKAAAAMAtzeOZ8rZt20qSWrdu7bTdMAzZbDbl5ORc89i4uDjFxsY6bbPb7dr3W7ancQAAAIBblselfPXq1R6/udNut1/jdhVKOQAAAPyP26V8+vTpeuSRR9SiRQsvxAEAAAD8j9v3lKekpKhChQpq3Lixxo0bp++//94buQAAAAC/4XYpT01N1bFjxzRkyBDt2LFDTZs2VeXKlRUbG6s1a9YoNzfXGzkBAAAAn+XR6ivh4eHq0aOHFi1apN9++03vvfeeLl68qJ49e6pUqVLq1auXPvnkE50/f97svAAAAIDP8XhJxMuCgoLUtm1bvf/++8rIyNCKFStUoUIF/f3vf9ekSZPMyAgAAAD4tAKV8pkzZ6p27doKDg5WcHCwateurbS0NI0ePVo7d+7Ua6+9ZlZOAAAAwGd5vCTiyJEjNXnyZA0ZMkRNmjSRJG3atEkvv/yyDh48qDFjxqhw4cKmBQUAAAB8lcelfOrUqfrwww/VrVu3vG2PPPKI6tSpoyFDhmjMmDGmBAQAAAB8nce3r+Tk5Khhw4b5tt911126dOlSgUIBAAAA/sTjUt6jRw9NnTo13/bp06frqaeeKlAoAAAAwJ+4dftKbGxs3tc2m00zZszQihUrFBMTI0navHmzMjIy1KtXL3NTAgAAAD7MrVKelpbm9P1dd90lSdq/f78kqVSpUipVqhSf8gkAAAC4wa1Snpqa6q0cAAAAgN8q8IcHAQAAACgYSjkAAABgMUo5AAAAYDFKOQAAAGAxm2EYhtUhAAAAAH/GTDkAAABgMbeWRPS2RuPWWB0BJtj6egtJ0lNzdliaA+aY17OeJGnzz6ctzQFzxFQpIUna9+sFa4PANFVLF5UkPfyvbRYngRmWPXu3JGn0yp8tTgIzvNmmistjmSkHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALBboyqDw8HDZbDaXTnjq1KkCBQIAAAD8jUul/O233/ZyDAAAAMB/uVTKe/fu7e0cAAAAgN9yqZT/p5ycHC1dulR79+6VzWZTjRo11LFjRwUGenQ6AAAAwK+53aJ3796tjh076vjx46pWrZokad++fSpVqpQ+++wzRUdHmx4SAAAA8GVul/IBAwaoVq1a+vbbbxUeHi5JyszMVJ8+ffTMM89o06ZNNzyHw+GQw+Fw2ma3292NAgAAAPgEt5dE3LlzpxITE/MKufTX6ixjx47Vjh07XDpHYmKiwsLCnB6JiYnuRgEAAAB8gtulvFq1avr111/zbT9x4oSqVKni0jni4uJ05swZp0dcXJy7UQAAAACf4NLtK2fPns37ety4cXrhhRc0atQoxcTESJI2b96s0aNHa8KECS49qd1u53YVAAAA4H+5VMpLlCjh9OFBhmGoa9euedsMw5AkdejQQTk5OV6ICQAAAPgul0p5ampq3tcHDx7UHXfcoYCAAKcxubm5ysjIMDcdAAAA4AdcKuXNmzfP+7pVq1Y6duyYIiIinMacPHlS999/v3r16mVuQgAAAMDHuf1GT8MwnG5luSwrK0vBwcGmhAIAAAD8icvrlMfGxkqSbDabRo4cqaJFi+bty8nJ0ZYtW1SvXj3TAwIAAAC+zuVSnpaWJumvmfJdu3YpKCgob19QUJDq1q2roUOHmp8QAAAA8HEul/LLb/bs27ev3nnnHRUvXtxroQAAAAB/4nIpvywpKckbOQAAAAC/5fYbPQEAAACYi1IOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFjMZhiGYXUIAAAAwJ8xUw4AAABYLNDqAFd6as4OqyPABPN61pMk7cw4Z20QmKLuHaFWR4AXJH+bYXUEmKRXwzskST8ev2BxEpihWmRRSdKUb9ItTgIzDGlW0eWxzJQDAAAAFqOUAwAAABajlAMAAAAWo5QDAAAAFqOUAwAAABajlAMAAAAWM7WUX7p0yczTAQAAAH7BlFK+Z88excbGqmzZsmacDgAAAPArHpfyrKwszZgxQ02aNFGdOnW0detWvfbaa2ZmAwAAAPyC25/ouWHDBs2YMUOLFy9WxYoVtWfPHq1du1bNmjXzRj4AAADA57k8Uz5x4kRVr15dTz75pEqVKqUNGzbou+++k81mU3h4uDczAgAAAD7N5Zny119/Xa+++qpGjx6tgIAAb2YCAAAA/IrLM+WjR4/Wxx9/rIoVK+rVV1/V7t27vZkLAAAA8Bsul/LXX39d+/bt05w5c3T8+HHFxMSobt26MgxDmZmZ3swIAAAA+DS3V19p3ry5PvroIx07dkyDBg3SXXfdpebNm6tp06aaNGmSNzICAAAAPs3jJRFDQ0M1cOBAbdmyRWlpaWrUqJHGjx9vZjYAAADAL5jy4UHR0dF6++239f3335txOgAAAMCvFLiUG4ahL7/8Up07d1a5cuXMyAQAAAD4Fbc/POiyAwcOaNasWfroo4+UlZWl9u3ba8GCBS4d63A45HA4nLbZ7XZPowAAAAC3NLdmyi9evKi5c+eqRYsWqlmzpnbu3Kljx45p/fr1mjt3rjp16uTSeRITExUWFub0SExM9OgFAAAAALc6l0v54MGDVaZMGb3//vt6/PHHdeTIEX3++eey2WwqVMi9u2Di4uJ05swZp0dcXJzb4QEAAABf4PLtK9OnT9err76q1157TaGhoQV6Urvdzu0qAAAAwP9yeYo7OTlZW7duVVRUlJ544gktW7ZMly5d8mY2AAAAwC+4XMq7d++ulStXavfu3apevbqee+45RUVFKTc3V3v27PFmRgAAAMCnub0kYoUKFZSQkKCDBw9qzpw56ty5s3r06KFy5crphRde8EZGAAAAwKd5vE65zWZT27ZttWjRIh09elTDhg1TcnKymdkAAAAAv1DgDw86c+aMFixYoI8++kjnzp0zIxMAAADgVzwu5atXr1aPHj0UFRWlKVOmqF27dvr222/NzAYAAAD4Bbc+0fOXX37R7NmzNWvWLJ0/f15du3ZVdna2Fi9erJo1a3orIwAAAODTXJ4pb9eunWrWrKk9e/ZoypQpOnr0qKZMmeLNbAAAAIBfcHmmfMWKFXrhhRc0aNAg3Xnnnd7MBAAAAPgVl2fK169fr3Pnzqlhw4Zq3Lix3nvvPf3222/ezAYAAAD4BZdLeZMmTfThhx/q2LFjevbZZ7VgwQKVLVtWubm5WrlyJSuvAAAAAB5ye/WVokWLql+/ftqwYYN27dqlV155RePHj1dERIQeeeQRb2QEAAAAfFqB1imvVq2aJk6cqF9++UUpKSlmZQIAAAD8SoE/PEiSAgIC9Oijj+qzzz4z43QAAACAXzGllAMAAADwHKUcAAAAsBilHAAAALCYzTAMw+oQAAAAgD9jphwAAACwWKDVAa705lc/WR0BJhj94J2SpIxTDouTwAx33GaXJK3c+7vFSWCGNjVul8T19CWXryl8y+iVP1sdASZ4s00Vl8cyUw4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWMy0Up6bm6vPP/9cjz76qFmnBAAAAPxCgUv5Tz/9pLi4OJUrV05du3Y1IxMAAADgVwI9OeiPP/7QokWLNHPmTG3evFk5OTmaPHmy+vXrp2LFipmdEQAAAPBpbs2Ub926Vc8884wiIyP13nvvqXPnzsrIyFChQoV0//33U8gBAAAAD7g1U960aVMNGTJEW7duVbVq1byVCQAAAPArbpXyVq1aaebMmTpx4oR69uypBx98UDabzVvZAAAAAL/g1u0rK1as0Pfff69q1app0KBBioqK0osvvihJlHMAAADAQ26vvnLHHXfozTffVHp6uubMmaMTJ04oMDBQHTt21Ouvv67t27d7IycAAADgswq0JGKbNm2UkpKio0ePasiQIVq+fLnuvvtus7IBAAAAfsGUDw8KDw/XkCFDlJaWpm3btplxSgAAAMBveLRO+dVkZmZq7ty5mjlzpnbs2HHdsQ6HQw6Hw2mb3W43KwoAAABwSynwTPnXX3+tbt26qUyZMpo4caKaN29+w2MSExMVFhbm9EhMTCxoFAAAAOCW5NFM+eHDh5WUlKSkpCRlZWUpMzNTixYtUufOnV06Pi4uTrGxsU7b7Ha7xq457EkcAAAA4Jbm1kz5okWL9MADD6hGjRravXu33nnnHR09elSFChVSjRo1XD6P3W5X8eLFnR7cvgIAAAB/5dZMeffu3TV8+HAtXrxYoaGh3soEAAAA+BW3Zsr79eunDz74QG3bttW0adOUmZnprVwAAACA33CrlE+fPl3Hjh3TM888o5SUFEVFRaljx44yDEO5ubneyggAAAD4NLdXXylSpIh69+6ttWvXateuXapRo4ZKly6tZs2aqXv37lqyZIk3cgIAAAA+q0BLIt55550aP368MjIyNG/ePF24cEHdunUzKxsAAADgFzwq5SdPnsz7OiMjQ6NGjdLatWsVGxurjIwM08IBAAAA/sCtUr5r1y5VqFBBERERql69unbs2KG7775bkydP1vTp09WqVStt3LjRW1kBAAAAn+RWKR8+fLiio6O1du1atWjRQg8//LDatWunM2fOKDMzU88++6zGjx/vrawAAACAT3JrnfJt27Zp9erVqlOnjurVq6fp06dr8ODBKlTor24/ZMgQxcTEeCUoAAAA4Kvcmik/deqUIiMjJUnFihVTSEiIbrvttrz94eHhOnfunLkJAQAAAB/n9hs9bTbbdb8HAAAA4B63bl+RpD59+shut0uSLl68qIEDByokJESS5HA4zE0HAAAA+AG3Snnv3r2dvu/Ro0e+Mb169SpYIgAAAMDPuFXKk5KSvJUDAAAA8FsF+kRPAAAAAAVHKQcAAAAsRikHAAAALGYzDMOwOgQAAADgz5gpBwAAACzm9jrl3tRu2larI8AEXw5sJEn6r+9/szgJzNC2VilJ0qR1ByxOAjPE3ldJkjT8ix8tTgKzTGxfTZK065csi5PADNHlikmSxq3ab3ESmOH11pVdHstMOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxSjkAAABgMUo5AAAAYDFKOQAAAGAxj0r5+fPnzc4BAAAA+C2PSnnp0qXVr18/bdiwwew8AAAAgN/xqJSnpKTozJkzat26tapWrarx48fr6NGjZmcDAAAA/IJHpbxDhw5avHixjh49qkGDBiklJUXly5fXww8/rCVLlujSpUtm5wQAAAB8VoHe6FmyZEm9/PLL2rlzpyZNmqSvv/5aXbp0UZkyZfTmm2/qwoULZuUEAAAAfFZgQQ4+fvy4kpOTlZSUpMOHD6tLly7q37+/jh49qvHjx2vz5s1asWJFvuMcDoccDofTNrvdXpAoAAAAwC3Lo1K+ZMkSJSUl6auvvlLNmjX13HPPqUePHipRokTemHr16ql+/fpXPT4xMVEJCQlO2+Lj46XIdp7EAQAAAG5pHpXyvn376sknn9Q333yju++++6pjKlWqpBEjRlx1X1xcnGJjY5222e12dUra6UkcAAAA4JbmUSk/duyYihYtet0xRYoU+Wv2+yrsdju3qwAAAAD/y6M3eoaGhurEiRP5tp88eVIBAQEFDgUAAAD4E49KuWEYV93ucDgUFBRUoEAAAACAv3Hr9pV3331XkmSz2TRjxgwVK1Ysb19OTo7WrVun6tWrm5sQAAAA8HFulfLJkydL+mumfNq0aU63qgQFBalChQqaNm2auQkBAAAAH+dWKU9PT5cktWzZUkuXLnVaAhEAAACAZ1wu5VcuYVi/fn2NHj36mmMnTZpUsFQAAACAH3G5lKelpbk0zmazeRwGAAAA8Ecul/LU1FRv5gAAAAD8lkdLIgIAAAAwD6UcAAAAsBilHAAAALAYpRwAAACwGKUcAAAAsBilHAAAALAYpRwAAACwGKUcAAAAsBilHAAAALCYzTAMw+oQAAAAgD9jphwAAACwWKDVAa70xe4TVkeACdrXjpAkvf7lPouTwAzj2lWVJNVPWG1xEpghLb6V1RHgJTszzlkdASaoe0eoJGnwkj0WJ4EZPnispstjmSkHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALOZRKc/IyNAvv/yS9/3WrVv10ksvafr06aYFAwAAAPyFR6W8e/fuSk1NlSQdP35cbdq00datW/X6669r9OjRpgYEAAAAfJ1HpXz37t1q1KiRJGnRokWqXbu2Nm7cqPnz52v27Nlm5gMAAAB8nkelPDs7W3a7XZL09ddf65FHHpEkVa9eXceOHTMvHQAAAOAHPCrltWrV0rRp07R+/XqtXLlSbdu2lSQdPXpUJUuWNDUgAAAA4Os8KuUTJkzQv/71L7Vo0ULdunVT3bp1JUmfffZZ3m0tAAAAAFwT6MlBLVq00O+//66zZ88qPDw8b/szzzyjokWLmhYOAAAA8AcelXJJCggIcCrkklShQoWC5gEAAAD8jsulvEGDBlq1apXCw8NVv3592Wy2a47dvn37dc/lcDjkcDictl1+4ygAAADgb1wu5R07dswrzh07drxuKb+RxMREJSQkOG2Lj4/X3V0Ge3xOAAAA4FblcimPj4/P+3rUqFEFetK4uDjFxsY6bbPb7fr6pzMFOi8AAABwK/Jo9ZVKlSrp5MmT+bafPn1alSpVuuHxdrtdxYsXd3pw+woAAAD8lUel/ODBg8rJycm33eFw6JdffilwKAAAAMCfuLX6ymeffZb39VdffaWwsLC873NycrRq1SpVrFjRvHQAAACAH3CrlD/66KOSJJvNpt69ezvtK1y4sCpUqKC33nrLtHAAAACAP3CrlOfm5kqSKlasqG3btun222/3SigAAADAn3j04UHp6elatWqVVq1apRMnTuSV9ctmzZplSjgAAADAH3hUykePHq2EhAQ1bNhQUVFRBVqzHAAAAPB3HpXyqVOnavbs2erZs6fZeQAAAAC/49GSiH/++aeaNm1qdhYAAADAL3lUygcMGKD58+ebnQUAAADwSx7dvnLx4kVNnz5dX3/9terUqaPChQs77Z80aZIp4QAAAAB/4FEp/+6771SvXj1J0u7du5328aZPAAAAwD0elfLU1FSzcwAAAAB+y6N7ygEAAACYh1IOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWMxmGIZhdQgAAADAnzFTDgAAAFjMo3XKAVd8uOWQ1RFggqcbl7c6Aryg2T/WWx0BJvlm2L2SpJ7zdlqcBGaY81RdSdLKvb9bnARmaFPjdpfHMlMOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYjFIOAAAAWIxSDgAAAFiMUg4AAABYLNDVgd99953LJ61Tp45HYQAAAAB/5HIpr1evnmw2mwzDuOr+y/tsNptycnJMCwgAAAD4OpdLeXp6ujdzAAAAAH7L5VLeqVMnrVq1SuHh4Ro9erSGDh2qokWLejMbAAAA4BdcfqPn3r17df78eUlSQkKCsrKyvBYKAAAA8Cdu3VPet29f3XPPPTIMQ//85z9VrFixq4598803TQsIAAAA+DqXS/ns2bMVHx+vZcuWyWazafny5QoMzH+4zWa7YSl3OBxyOBxO2+x2u+x2u6txAAAAAJ/hcimvVq2aFixYIEkqVKiQVq1apYiICI+eNDExUQkJCU7b4uPjNWrUKI/OBwAAANzKXC7lV8rNzS3Qk8bFxSk2NtZpG7PkAAAA8FcelXJJ2rdvn9asWaMTJ07kK+k3un2FW1UAAACA/+NRKf/www81aNAg3X777YqMjJTNZsvb58o95QAAAAD+j0elfMyYMRo7dqxeffVVs/MAAAAAfsfldcqvlJmZqccff9zsLAAAAIBf8qiUP/7441qxYoXZWQAAAAC/5NHtK1WqVNHIkSO1efNmRUdHq3Dhwk77X3jhBVPCAQAAAP7Ao1I+ffp0FStWTGvXrtXatWud9tlsNko5AAAA4AaPSnl6errZOQAAAAC/5XIpj42N1d///neFhITk++CfK9lsNr311lumhAMAAAD8gculPC0tTdnZ2XlfX8uVa5YDAAAAuDGXS3lqaupVvwYAAABQMB4tiQgAAADAPJRyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBilHIAAADAYjbDMAyrQwAAAAD+jJlyAAAAwGIuf6InAMB3nP4jx+oIMEmJIgGSpM0/n7Y2CEwRU6WEJGn/iT+sDQJTVI4o4vJYZsoBAAAAi1HKAQAAAItRygEAAACLUcoBAAAAi1HKAQAAAItRygEAAACLUcoBAAAAi1HKAQAAAItRygEAAACLUcoBAAAAi1HKAQAAAItRygEAAACLUcoBAAAAi1HKAQAAAIu5XcoNw9ChQ4f0xx9/eCMPAAAA4Hc8KuV33nmnfvnlF2/kAQAAAPyO26W8UKFCuvPOO3Xy5Elv5AEAAAD8jkf3lE+cOFHDhg3T7t27zc4DAAAA+J1ATw7q0aOHLly4oLp16yooKEhFihRx2n/q1KnrHu9wOORwOJy22e122e12T+IAAAAAtzSPSvnkyZNls9k8ftLExEQlJCQ4bYuPj9eoUaM8PicAAABwq7IZhmHc7CdlphwArHX6jxyrI8AkJYoESJI2/3za2iAwRUyVEpKk/SdY5c4XVI4ocuNB/8ujmfKAgAAdO3ZMERERTttPnjypiIgI5eRc/x97CjgAAADwfzx6o+e1JtcdDoeCgoIKFAgAAADwN27NlL/77ruSJJvNphkzZqhYsWJ5+3JycrRu3TpVr17d3IQAAACAj3OrlE+ePFnSXzPl06ZNU0BAQN6+oKAgVahQQdOmTTM3IQAAAODj3Crl6enpkqSWLVtq6dKlKlGihDcyAQAAAH7F5dVXYmNjXT7ppEmTPA4EAPA+Vl/xHay+4ltYfcW3eGX1lbS0NJfGFWT9cgAAAMAfuVzKU1NTvZkDAAAA8FseLYkIAAAAwDyUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGI2wzAMq0MAAAAA/oyZcgAAAMBigVYHgO/afvCs1RFgggYVikuS1u07ZXESmOG+qrdJkr4/ct7iJDBLrbIhkqTNP5+2NghMEVOlhCRpyjfp1gaBKYY0q+jyWGbKAQAAAItRygEAAACLUcoBAAAAi1HKAQAAAItRygEAAACLUcoBAAAAi7ldyrOzs9WyZUvt27fPG3kAAAAAv+N2KS9cuLB2794tm83mjTwAAACA3/Ho9pVevXpp5syZZmcBAAAA/JJHn+j5559/asaMGVq5cqUaNmyokJAQp/2TJk0yJRwAAADgDzwq5bt371aDBg0kKd+95dzWAgAAALjHo1Kemppqdg4AAADAb7EkIgAAAGAxj2bKJWnbtm36+OOPdfjwYf35559O+5YsWVLgYAAAAIC/8GimfMGCBWrWrJn27NmjpUuXKjs7W3v27NHq1asVFhZmdkYAAADAp3lUyseNG6fJkydr2bJlCgoK0jvvvKO9e/eqa9eu+tvf/mZ2RgAAAMCneVTK9+/fr/bt20uS7Ha7zp8/L5vNppdfflnTp083NSAAAADg6zwq5bfddpvOnTsnSSpbtqx2794tSTp9+rQuXLhgXjoAAADAD3j0Rs97771XK1euVHR0tLp27aoXX3xRq1ev1sqVK9W6desbHu9wOORwOJy22e122e12T+IAAAAAtzSPZsrfe+89Pfnkk5KkuLg4DR06VL/++qsee+wxzZw584bHJyYmKiwszOmRmJjoSRQAAADglmczDMO42U/KTLl/2H7wrNURYIIGFYpLktbtO2VxEpjhvqq3SZK+P3Le4iQwS62yIZKkzT+ftjYITBFTpYQkaco36dYGgSmGNKvo8liPZspbtmypmTNn6syZM54cLrvdruLFizs9KOQAAADwVx6V8ujoaL3xxhuKjIxU586d9emnn+b7ACEAAAAArvGolL/77rs6cuSI/v3vfys0NFS9e/dWZGSknnnmGa1du9bsjAAAAIBP86iUS1KhQoX0wAMPaPbs2fr111/1r3/9S1u3blWrVq3MzAcAAAD4PI+WRLzS8ePHtWDBAs2dO1ffffed7r77bjNyAQAAAH7Do5nys2fPKikpSW3atNEdd9yhqVOnqkOHDtq3b5+2bNlidkYAAADAp3k0U166dGmFh4era9euGjduHLPjAAAAQAF4VMoXLlyoFi1aqHjxv9YvPnTokJYuXaoaNWrowQcfNDUgAAAA4Os8KuXvvfeejh49qoEDB+r06dNq1KiRgoKC9Pvvv2vSpEkaNGiQ2TkBAAAAn+XRPeXbt2/XvffeK0n65JNPFBkZqUOHDik5OVnvvvuuqQEBAAAAX+dRKb9w4YJCQ0MlSStWrNBjjz2mQoUKKSYmRocOHTI1IAAAAODrPCrlVapU0aeffqqMjAx99dVXeuCBByRJJ06cyLvPHAAAAIBrPCrlb775poYOHaoKFSqocePGatKkiaS/Zs3r169vakAAAADA13n0Rs8uXbronnvu0bFjx1S3bt287a1bt1anTp1MCwcAAAD4A48/0TMyMlKRkZFO2xo1alTgQAAAAIC/8ej2FQAAAADmoZQDAAAAFqOUAwAAABazGYZhWB0CAAAA8GfMlN9EDodDo0aNksPhsDoKTMD19C1cT9/DNfUtXE/fwvXMj5nym+js2bMKCwvTmTNn+JAlH8D19C1cT9/DNfUtXE/fwvXMj5lyAAAAwGKUcgAAAMBilHIAAADAYpTym8hutys+Pl52u93qKDAB19O3cD19D9fUt3A9fQvXMz/e6AkAAABYjJlyAAAAwGKUcgAAAMBilHIAAADAYpRyAAAAwGKU8gLq06ePbDabbDabChcurEqVKmno0KE6f/583pjFixerRYsWCgsLU7FixVSnTh2NHj1ap06dkiQdO3ZM3bt3V7Vq1VSoUCG99NJLFr0amHE9lyxZojZt2qhUqVIqXry4mjRpoq+++sqql+TXzLieGzZsULNmzVSyZEkVKVJE1atX1+TJk616SX7NjOt5pW+++UaBgYGqV6/eTXwVuJIZ13TNmjV557jy8cMPP1j1svyWWb+jDodDI0aMUPny5WW321W5cmXNmjXLipd0U1HKTdC2bVsdO3ZMBw4c0JgxY/TBBx9o6NChkqQRI0boiSee0N13363ly5dr9+7deuutt7Rz507NmTNH0l//4ytVqpRGjBihunXrWvlSoIJfz3Xr1qlNmzb68ssv9d///d9q2bKlOnTooLS0NCtflt8q6PUMCQnR888/r3Xr1mnv3r1644039MYbb2j69OlWviy/VdDredmZM2fUq1cvtW7d2oqXgSuYdU1//PFHHTt2LO9x5513WvFy/J4Z17Nr165atWqVZs6cqR9//FEpKSmqXr26VS/p5jFQIL179zY6duzotG3AgAFGZGSksWXLFkOS8fbbb1/12MzMzHzbmjdvbrz44ovmB4VLzL6el9WsWdNISEgwMSlc4a3r2alTJ6NHjx4mJoUrzLyeTzzxhPHGG28Y8fHxRt26db0TGDdkxjVNTU01JF33dxY3hxnXc/ny5UZYWJhx8uRJL6f9/4eZci8oUqSIsrOzNW/ePBUrVkyDBw++6rgSJUrc3GDwSEGvZ25urs6dO6fbbrvNiynhqoJez7S0NG3cuFHNmzf3Ykq4ypPrmZSUpP379ys+Pv4mpYQ7PP0drV+/vqKiotS6dWulpqbehKRwhbvX87PPPlPDhg01ceJElS1bVlWrVtXQoUP1xx9/3MTU1gi0OoCv2bp1q+bPn6/WrVvrp59+UqVKlVS4cGGrY8FDZlzPt956S+fPn1fXrl29lBKuKsj1LFeunH777TddunRJo0aN0oABA7ycFjfiyfX86aef9Nprr2n9+vUKDOQ/gf/feHJNo6KiNH36dN11111yOByaM2eOWrdurTVr1ui+++67SclxNZ5czwMHDmjDhg0KDg7W0qVL9fvvv2vw4ME6deqUz99Xzky5CZYtW6ZixYopODhYTZo00X333acpU6bIMAzZbDar48FNZl7PlJQUjRo1SgsXLlRERISXEuN6zLqe69ev17fffqtp06bp7bffVkpKihdT41oKcj1zcnLUvXt3JSQkqGrVqjcpMW6koL+j1apV09NPP60GDRqoSZMm+uCDD9S+fXv985//vAnp8Z8Kej1zc3Nls9k0b948NWrUSO3atdOkSZM0e/Zsn58tZ5rABC1bttTUqVNVuHBhlSlTJu+vwKpVq2rDhg3Kzs5mtvwWYtb1XLhwofr376+PP/5Y999/v7dj4xrMup4VK1aUJEVHR+vXX3/VqFGj1K1bN69mR34FuZ7nzp3Tt99+q7S0ND3//POS/ioAhmEoMDBQK1asUKtWrW7aa8FfvPHf0JiYGM2dO9cbcXEDBb2eUVFRKlu2rMLCwvK21ahRQ4Zh6JdffvHpN/AyU26CkJAQValSReXLl3f6H1r37t2VlZWlDz744KrHnT59+iYlhDvMuJ4pKSnq06eP5s+fr/bt23s7Mq7DG7+fhmHI4XCYHRUuKMj1LF68uHbt2qUdO3bkPQYOHKhq1appx44daty48c16GbiCN35H09LSFBUVZXZUuKCg17NZs2Y6evSosrKy8vbt27dPhQoVUrly5bya3WrMlHtR48aNNXz4cL3yyis6cuSIOnXqpDJlyujnn3/WtGnTdM899+jFF1+UJO3YsUOSlJWVpd9++007duxQUFCQatasaeErwJVcvZ4pKSnq1auX3nnnHcXExOj48eOS/nqzy5V/+cNarl7P999/X3/729/yluPasGGD/vnPf2rIkCEWvwJcydXrWbt2bafjIiIiFBwcnG87rOfqNX377bdVoUIF1apVS3/++afmzp2rxYsXa/HixVa/BFzB1evZvXt3/f3vf1ffvn2VkJCg33//XcOGDVO/fv1UpEgRq1+Gd1m27ouPuNryP/9p4cKFxn333WeEhoYaISEhRp06dYzRo0c7Ld8kKd+jfPnyXs2O/My4ns2bN7/q9ezdu7fX88OZGdfz3XffNWrVqmUULVrUKF68uFG/fn3jgw8+MHJycrz/AuDErH9vr8SSiNYy45pOmDDBqFy5shEcHGyEh4cb99xzj/HFF194PzzyMet3dO/evcb9999vFClSxChXrpwRGxtrXLhwwbvh/x+wGYZhWPUHAQAAAADuKQcAAAAsRykHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACxGKQcAAAAsRikHAAAALEYpBwAAACz2P5zeerO8FmfIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Vector Heatmap\n",
    "pca_comp_df = pd.DataFrame(pca.components_.T, index=X.columns, columns=[\"PC%i\" % i for i in range(1,n+1)])\n",
    "f, ax = plt.subplots(figsize = (9,6))\n",
    "new_blues=sns.color_palette(\"Blues\", 100)[0:70]         # 设置颜色参数，基调为蓝色\n",
    "sns.heatmap(pca_comp_df, mask=(abs(pca_comp_df)<0.05), cmap=new_blues, yticklabels=True, linewidths = 0.005, linecolor= 'white', ax = ax, cbar = False)\n",
    "ax.set_title('PCA Loading Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded1357",
   "metadata": {},
   "source": [
    "## 2. Partial Least Squares Regression (PLS)\n",
    "\n",
    "- **Basic Principles and Mathematical Formulation**\n",
    "  - Core ideas:\n",
    "    - Extract components in the directions of maximum covariance between X and Y to address multicollinearity and high-dimensional problems.\n",
    "    - Iterative algorithm based on target information  \n",
    "      1. **Initialization**:  \n",
    "         $ z_{t,0} = y_{t+h} $\n",
    "      2. **For the k-th component (k = 1,...,r), compute as follows**:  \n",
    "         - **Time-series regression to estimate $\\hat{A_i}$**:  \n",
    "           $ X_{it} = a_i + z'_{t,k-1}A_i + v_{i,t} $\n",
    "         - **Cross-sectional regression at time t to estimate $\\hat{B_t}$**:  \n",
    "           $ X_{it} = \\hat{A}_iB_t + v_{i,t}^* $\n",
    "         - **Forecast regression**:  \n",
    "           $ y_{t+h} = \\alpha + \\hat{B}_t\\beta + \\epsilon_{t+h} $\n",
    "      3. **Update residuals and iterate Step 2**:  \n",
    "         $ z_k = (z_{k-1}, \\hat{\\epsilon}^{(k)}) $, until the r-th component is obtained.\n",
    "\n",
    "- **Comparison with Traditional Methods**\n",
    "\n",
    "| Feature             | OLS                | PLS                          |\n",
    "|---------------------|--------------------|------------------------------|\n",
    "| **Matrix requirement** | $X'X$ invertible   | No requirement               |\n",
    "| **Collinearity handling** | Fails              | Effective                    |\n",
    "| **Component interpretation** | None             | Clear optimization target    |\n",
    "| **Small-sample performance** | Overfitting       | Stable                       |\n",
    "\n",
    "- **Advantages and Limitations**\n",
    "  - Advantages:\n",
    "    1. **Robust to multicollinearity**: avoids directly inverting the $X'X$ matrix.\n",
    "    2. **Suitable for small samples**: effective when $n < p$.\n",
    "    3. **Dual dimensionality reduction**: considers both X and Y structures simultaneously.\n",
    "  - Limitations:\n",
    "    1. **Sensitive to variable count**: requires at least 3 variables.\n",
    "    2. **Interpretation complexity**: economic meaning of components is not intuitive.\n",
    "    3. **Cumulative contribution risk**: may not reach threshold requirements.\n",
    "\n",
    "- **Extended Applications**\n",
    "\n",
    "  - **Dynamic PLS (DPLS)**\n",
    "    - **Improvements**:\n",
    "      - Incorporates time-series structure.\n",
    "      - Objective function:  \n",
    "        $$\n",
    "        \\max \\sum_{t=1}^T \\text{Cov}^2(X_tw, Y_{t+h})\n",
    "        $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afbb7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ba26c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01378983, -0.01279426,  0.07122543,  0.01949301,  0.00196856,\n",
       "         0.00366652, -0.01570974,  0.00159726,  0.02427304,  0.05982686,\n",
       "        -0.12885449]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLS analysis\n",
    "n = 4\n",
    "pls = PLSRegression(n_components=n)\n",
    "pls.fit(X_normed, y)\n",
    "X_pls = pls.transform(X_normed)\n",
    "pls.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9288e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PLS Weight Matrix')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLS Weight Matrix Heatmap\n",
    "pls_comp_df = pd.DataFrame(pls.x_weights_, index=X_normed.columns, columns=[\"PC%i\" % i for i in range(1,n+1)])\n",
    "f, ax = plt.subplots(figsize = (9,6))\n",
    "new_blues=sns.color_palette(\"Blues\", 100)[0:70]        \n",
    "sns.heatmap(pls_comp_df, mask=(abs(pls_comp_df)<0.05), cmap=new_blues, yticklabels=True, linewidths = 0.005, linecolor= 'white', ax = ax, cbar = False)\n",
    "ax.set_title('PLS Weight Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3434f62",
   "metadata": {},
   "source": [
    "### A comprehensive forecasting application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7397204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_R_OOS_2(y_oos_bar, y_oos, y_hat_oos):\n",
    "    \"\"\"\n",
    "    Calculate the out-of-sample predictive R-squared statistic (R2_OOS),\n",
    "    used to evaluate a forecasting model relative to the historical mean benchmark.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    y_oos_bar : array-like\n",
    "        Benchmark forecast values computed using the historical mean (naive forecast).\n",
    "    y_oos : array-like\n",
    "        Sequence of actual out-of-sample observed values.\n",
    "    y_hat_oos : array-like\n",
    "        Out-of-sample forecast values generated by the predictive model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        R2_OOS in percentage form (range: 0-100), rounded to 2 decimal places.  \n",
    "        A positive value indicates the model outperforms the historical mean benchmark.\n",
    "    \n",
    "    Algorithm\n",
    "    ---------\n",
    "    1. Compute the model's mean squared forecast error (MSFE_model).\n",
    "    2. Compute the benchmark (historical mean) mean squared forecast error (MSFE_benchmark).\n",
    "    3. R2_OOS = (1 - MSFE_model / MSFE_benchmark) * 100\n",
    "    4. As a rule of thumb, R2_OOS > 2% is considered economically meaningful.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = np.sum((y_oos - y_hat_oos) ** 2)\n",
    "    denominator = np.sum((y_oos - y_oos_bar) ** 2)\n",
    "    R_OOS_2 = round((1 - numerator / denominator) * 100, 2)\n",
    "    return R_OOS_2\n",
    "\n",
    "\n",
    "def calculate_DM_statistic(e1_t, e2_t, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform the Diebold–Mariano (DM) test to compare the predictive accuracy \n",
    "    of two forecasting models.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    e1_t : array-like\n",
    "        Forecast error series of Model 1 (actual value - predicted value).\n",
    "    e2_t : array-like\n",
    "        Forecast error series of Model 2.\n",
    "    alpha : float, optional\n",
    "        Significance level threshold (default = 0.05).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (DM statistic, p-value)\n",
    "        \n",
    "    Test Description\n",
    "    ----------------\n",
    "    1. Null hypothesis: Predictive accuracy of Model 1 = Model 2.\n",
    "    2. Alternative hypothesis: Predictive accuracy of Model 1 < Model 2.\n",
    "    3. The test statistic is constructed from the standardized mean \n",
    "       of the squared error differences.\n",
    "    4. Applicable for comparing non-nested models.\n",
    "    \"\"\"\n",
    "    d_12t = (e1_t ** 2) - (e2_t ** 2)\n",
    "    T = len(d_12t)\n",
    "    d_bar_12 = np.mean(d_12t)\n",
    "    std_d_bar_12 = np.std(d_12t, ddof=1) / np.sqrt(T)\n",
    "    DM_statistic = d_bar_12 / std_d_bar_12\n",
    "    p_value = 1 - stats.norm.cdf(DM_statistic)\n",
    "    return DM_statistic, p_value\n",
    "\n",
    "\n",
    "def calculate_CW_statistic(r_set):\n",
    "    \"\"\"\n",
    "        Compute the Clark-West (CW) statistic, designed for comparing \n",
    "        the predictive accuracy of nested models.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        r_set : DataFrame\n",
    "            Must contain three columns:\n",
    "            - r_real: actual observed values\n",
    "            - r_bar: benchmark forecast from the historical mean\n",
    "            - r_hat: model forecast values\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            CW statistic (adjusted MSPE statistic)\n",
    "            \n",
    "        Method Features\n",
    "        ---------------\n",
    "        1. A modified Diebold-Mariano test specifically for nested models.\n",
    "        2. Corrects the bias in nested model comparison by adjusting forecast errors.\n",
    "        3. Employs HAC standard errors to handle autocorrelation.\n",
    "        4. The statistic is asymptotically standard normal.\n",
    "    \"\"\"\n",
    "    r_set['u0_hat2'] = (r_set['r_real'] - r_set['r_bar']) ** 2     # baseline model error\n",
    "    r_set['ui_hat2'] = (r_set['r_real'] - r_set['r_hat']) ** 2     # predictive model error\n",
    "    r_set['d'] = r_set['u0_hat2'] - (r_set['ui_hat2'] - (r_set['r_bar'] - r_set['r_hat']) ** 2)\n",
    "    N = r_set.dropna().shape[0]\n",
    "    L = int(np.ceil(4 * (N / 100) ** (2 / 9)))\n",
    "    X = sm.add_constant(r_set['d'].to_numpy())\n",
    "    y = r_set['r_real'].to_numpy()\n",
    "    reg = sm.OLS(y, X)\n",
    "    result = reg.fit(cov_type='HAC', use_t=True, cov_kwds={'maxlags': L})\n",
    "    CW_statistic = result.tvalues[0].astype(float).round(4)\n",
    "    p_value = 1 - stats.norm.cdf(CW_statistic)\n",
    "    \n",
    "    return CW_statistic, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbcba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_method(in_X_train, in_y_train, in_X_test, in_y_test, in_X_oos, in_test_data, in_oos_data):\n",
    "    \"\"\"\n",
    "        Perform dimensionality reduction using Principal Component Analysis (PCA),\n",
    "        and fit a linear regression model on the reduced data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        in_X_train : array-like\n",
    "            Training feature data (used to estimate parameters).\n",
    "        in_y_train : array-like\n",
    "            Training target variable.\n",
    "        in_X_test : array-like\n",
    "            Test feature data (used to select the optimal hyperparameter).\n",
    "        in_y_test : array-like\n",
    "            Test target variable.\n",
    "        in_X_oos : array-like\n",
    "            Out-of-sample feature data (used to evaluate model performance).\n",
    "        in_test_data : DataFrame\n",
    "            Test set including date and target variable.\n",
    "        in_oos_data : DataFrame\n",
    "            Out-of-sample data including date and target variable.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        ret_oos : dict\n",
    "            Prediction results for all numbers of principal components.\n",
    "        data_pca : DataFrame\n",
    "            Prediction results using the optimal number of principal components.\n",
    "        importance_dict : dict\n",
    "            Principal component importance (explained variance ratio).\n",
    "        exp_ratio_dict : dict\n",
    "            Cumulative explained variance ratio.\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    # initialize variables to store results\n",
    "    mse = []  # store mean squared error for different numbers of principal components\n",
    "    ret_test = []\n",
    "    ret_oos = []  # store prediction results for all numbers of principal components\n",
    "    importance_dict = {}  # store principal component importance\n",
    "    exp_ratio_dict = {}  # store cumulative explained variance ratio\n",
    "\n",
    "    ## Test set: Estimate hyperparameters\n",
    "    # Iterate over different numbers of principal components (1 to 8)\n",
    "    prespecific_PCs = [i for i in range(1,9)]\n",
    "    for i in prespecific_PCs:\n",
    "        # Initialize PCA model\n",
    "        pca = PCA(n_components=i)\n",
    "        pca.fit(in_X_train)  # Fit PCA model\n",
    "\n",
    "        # Extract principal component importance and cumulative explained variance ratio\n",
    "        importance = list(pca.explained_variance_ratio_)\n",
    "        exp_ratio = pd.Series(pca.explained_variance_ratio_).cumsum()\n",
    "\n",
    "        # Store results in the dictionary\n",
    "        importance_dict[i] = importance\n",
    "        exp_ratio_dict[i] = exp_ratio\n",
    "\n",
    "        # Transform validation set using PCA\n",
    "        X_pca = pca.transform(in_X_train)\n",
    "        Y = np.array(in_y_train)  # Convert target variable to array\n",
    "        X_pca = np.array(X_pca)  # Convert PCA results to array\n",
    "        model = LinearRegression()\n",
    "        reg = model.fit(X_pca, Y)\n",
    "\n",
    "        # Compute mean squared error\n",
    "        Xtest_pca = pca.transform(in_X_test)\n",
    "        Xtest_pca = np.array(Xtest_pca)\n",
    "        ytest_hat = reg.predict(Xtest_pca)\n",
    "        res1 = 1 - np.sum((in_y_test - ytest_hat) ** 2) / np.sum(in_y_test ** 2)\n",
    "        ret_test.append(res1)\n",
    "\n",
    "        # Fit linear regression model on PCA-transformed data\n",
    "        model1 = LinearRegression()\n",
    "        lin_reg = model1.fit(X_pca, Y)\n",
    "\n",
    "        # Transform out-of-sample data using PCA and predict\n",
    "        Xoos_pca = pca.transform(in_X_oos)\n",
    "        Xoos_pca = np.array(Xoos_pca)\n",
    "        yhat = lin_reg.predict(Xoos_pca)\n",
    "\n",
    "        # Copy out-of-sample data and add predictions\n",
    "        inner_oos_data = in_oos_data.copy()\n",
    "        inner_oos_data['rethat'] = yhat\n",
    "\n",
    "        # Extract date, actual values, and predicted values\n",
    "        data_pca = inner_oos_data[['Dates', 'y', 'rethat']]\n",
    "        data_pca.columns = ['Dates', 'y', 'yhat']  # Rename columns\n",
    "        data_pca['model'] = 'pca'                  # Mark model type as PCA\n",
    "        data_pca['n'] = i                          # Mark number of components\n",
    "        ret_oos.append(data_pca)\n",
    "\n",
    "    # Find the optimal number of components (the one with the lowest MSE)\n",
    "    optimal_comp = prespecific_PCs[ret_test.index(max(ret_test))]\n",
    "    print(f\"The optimal PC number: {optimal_comp}\")\n",
    "    \n",
    "    ## Train set: Estimate model parameters\n",
    "    # Refit PCA and linear regression model using the optimal number of principal components\n",
    "    pca_best = PCA(n_components=optimal_comp)\n",
    "    pca_best.fit(in_X_train)\n",
    "    X_pca = pca_best.transform(in_X_train)\n",
    "    Y = np.array(in_y_train)\n",
    "    X_pca = np.array(X_pca)\n",
    "    model1 = LinearRegression()\n",
    "    lin_reg = model1.fit(X_pca, Y)\n",
    "\n",
    "    ## Out-of-sample\n",
    "    # Predict on out-of-sample data\n",
    "    Xoos_pca = pca_best.transform(in_X_oos)\n",
    "    Xoos_pca = np.array(Xoos_pca)\n",
    "    yhat = lin_reg.predict(Xoos_pca)\n",
    "\n",
    "    # Copy out-of-sample data and add predictions\n",
    "    inner_oos_data = in_oos_data.copy()\n",
    "    inner_oos_data['rethat'] = yhat\n",
    "\n",
    "    # Extract date, actual values, and predicted values\n",
    "    data_pca = inner_oos_data[['Dates', 'y', 'rethat']]\n",
    "    data_pca.columns = ['Dates', 'y', 'yhat']\n",
    "\n",
    "    return pd.concat(ret_oos), data_pca, importance_dict, exp_ratio_dict\n",
    "\n",
    "\n",
    "def PLS_method(in_X_train,in_y_train,in_X_test,in_y_test,in_X_oos, in_test_data, in_oos_data):\n",
    "    \"\"\"\n",
    "    Apply Principal Component Analysis (PCA) for dimensionality reduction,\n",
    "    and fit a linear regression model on the reduced data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_X_train : array-like\n",
    "        Training feature data (used to estimate parameters).\n",
    "    in_y_train : array-like\n",
    "        Training target variable.\n",
    "    in_X_test : array-like\n",
    "        Test feature data (used to select the optimal hyperparameter).\n",
    "    in_y_test : array-like\n",
    "        Test target variable.\n",
    "    in_X_oos : array-like\n",
    "        Out-of-sample feature data (used to evaluate model performance).\n",
    "    in_test_data : DataFrame\n",
    "        Test dataset including date and target variable.\n",
    "    in_oos_data : DataFrame\n",
    "        Out-of-sample dataset including date and target variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret_oos : dict\n",
    "        Prediction results for all numbers of principal components.\n",
    "    data_pca : DataFrame\n",
    "        Prediction results using the optimal number of principal components.\n",
    "    importance_dict : dict\n",
    "        Importance of each principal component (explained variance ratio).\n",
    "    exp_ratio_dict : dict\n",
    "        Cumulative explained variance ratio.\n",
    "    \"\"\"\n",
    "    from sklearn.cross_decomposition import PLSRegression, PLSCanonical\n",
    "    ret_test = []\n",
    "    ret_oos = []\n",
    "    coef_ser = {}\n",
    "    prespecific_k = [i for i in range(1,9)]\n",
    "    for k in prespecific_k:  \n",
    "        pls = PLSRegression(n_components=k, scale=False, copy=True)\n",
    "        pls.fit(in_X_train, in_y_train)\n",
    "        ytest_hat = pls.predict(in_X_test)\n",
    "        res1 = 1 - np.sum((in_y_test - ytest_hat) ** 2) / np.sum(in_y_test ** 2)\n",
    "        ret_test.append(res1)\n",
    "    \n",
    "        Yoos_pls = np.matrix(pls.predict(in_X_oos)).T\n",
    "        inner_oos_data = in_oos_data.copy()\n",
    "        inner_oos_data['rethat'] = Yoos_pls\n",
    "\n",
    "        data_pls = inner_oos_data[['Dates','y','rethat']]\n",
    "        data_pls.columns = ['Dates','y','yhat']\n",
    "        data_pls['model'] = 'pls' \n",
    "        data_pls['n'] = k\n",
    "\n",
    "        coef_ser[k] = pd.Series(pls.coef_[0] , index = in_X_train.columns)\n",
    "        ret_oos.append(data_pls)\n",
    "        \n",
    "        \n",
    "    optimal_comp = prespecific_k[ret_test.index(max(ret_test))]\n",
    "    \n",
    "    pls_best = PLSRegression(n_components=optimal_comp, scale=False, copy=True)\n",
    "    pls_best.fit(in_X_train, in_y_train)\n",
    "    yhat = pls_best.predict(in_X_oos)\n",
    "    \n",
    "    inner_oos_data = in_oos_data.copy()\n",
    "    inner_oos_data['rethat'] = yhat\n",
    "    inner_oos_data = in_oos_data.copy()\n",
    "    inner_oos_data['rethat'] = yhat\n",
    "    \n",
    "    data_pls = inner_oos_data[['Dates','y','rethat']]\n",
    "    data_pls.columns = ['Dates','y','yhat']\n",
    "\n",
    "    return pd.concat(ret_oos), data_pls, coef_ser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f957b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01378983, -0.01279426,  0.07122543,  0.01949301,  0.00196856,\n",
       "        0.00366652, -0.01570974,  0.00159726,  0.02427304,  0.05982686,\n",
       "       -0.12885449])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bac915f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sPCA_method(in_X_train, in_y_train, in_X_test, in_y_test, in_X_oos, in_test_data, in_oos_data):\n",
    "    \"\"\"\n",
    "        Apply scaled Principal Component Analysis (sPCA) for dimensionality reduction,\n",
    "        and fit a linear regression model on the reduced data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_X_train: array-like\n",
    "            Training feature data (used to estimate parameters).\n",
    "        in_y_train: array-like\n",
    "            Training target variable.\n",
    "        in_X_test: array-like\n",
    "            Test feature data (used to select the optimal hyperparameter).\n",
    "        in_y_test: array-like\n",
    "            Test target variable.\n",
    "        in_X_oos: array-like\n",
    "            Out-of-sample feature data (used to evaluate model performance).\n",
    "        in_test_data: DataFrame\n",
    "            Test dataset including date and target variable.\n",
    "        in_oos_data: DataFrame\n",
    "            Out-of-sample dataset including date and target variable.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ret_oos: dict\n",
    "            Prediction results for all numbers of principal components.\n",
    "        data_pca: DataFrame\n",
    "            Prediction results using the optimal number of principal components.\n",
    "        importance_dict: dict\n",
    "            Importance of each principal component (explained variance ratio).\n",
    "        exp_ratio_dict: dict\n",
    "            Cumulative explained variance ratio.\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    # initialize variables to store results\n",
    "    mse = []  # store mean squared error for different numbers of principal components\n",
    "    ret_test = []\n",
    "    ret_oos = []  # store prediction results for all numbers of principal components\n",
    "    importance_dict = {}  # store principal component importance\n",
    "    exp_ratio_dict = {}  # store cumulative explained variance ratio\n",
    "\n",
    "    ## Test set: Estimate hyperparameters\n",
    "    # Iterate over different numbers of principal components (1 to 8)\n",
    "    prespecific_PCs = [i for i in range(1,9)]\n",
    "    for i in prespecific_PCs:\n",
    "\n",
    "        # Generate weighted-data\n",
    "        Weighted_X_train = in_X_train.copy(deep=True)\n",
    "        Weighted_X_Test = in_X_test.copy(deep=True)\n",
    "        Weighted_X_oos = in_X_oos.copy(deep=True)\n",
    "        for Variable in in_X_train.columns:\n",
    "            sPCA_X = in_X_train[Variable]\n",
    "            sPCA_X = sm.add_constant(sPCA_X, has_constant='add')    \n",
    "            model = sm.OLS(in_y_train, sPCA_X)\n",
    "            results = model.fit()\n",
    "            param = results.params[Variable]\n",
    "            Weighted_X_train[Variable] = in_X_train[Variable] * param\n",
    "            Weighted_X_Test[Variable] = in_X_test[Variable] * param\n",
    "            Weighted_X_oos[Variable] = in_X_oos[Variable] * param\n",
    "\n",
    "        # Initialize PCA model\n",
    "        pca = PCA(n_components=i)\n",
    "        pca.fit(Weighted_X_train)  # Fit PCA model\n",
    "\n",
    "        # Extract principal component importance and cumulative explained variance ratio\n",
    "        importance = list(pca.explained_variance_ratio_)\n",
    "        exp_ratio = pd.Series(pca.explained_variance_ratio_).cumsum()\n",
    "\n",
    "        # Store results in the dictionary\n",
    "        importance_dict[i] = importance\n",
    "        exp_ratio_dict[i] = exp_ratio\n",
    "\n",
    "        # Perform PCA transformation\n",
    "        X_pca = pca.transform(Weighted_X_train)\n",
    "        Y = np.array(in_y_train)  # Convert target variable to array\n",
    "        X_pca = np.array(X_pca)  # Convert PCA results to array\n",
    "        model = LinearRegression()\n",
    "        reg = model.fit(X_pca, Y)\n",
    "\n",
    "        # Calculate mean squared error\n",
    "        Xtest_pca = pca.transform(Weighted_X_Test)\n",
    "        Xtest_pca = np.array(Xtest_pca)\n",
    "        ytest_hat = reg.predict(Xtest_pca)\n",
    "        res1 = 1 - np.sum((in_y_test - ytest_hat) ** 2) / np.sum(in_y_test ** 2)\n",
    "        ret_test.append(res1)\n",
    "\n",
    "        # Fit linear regression model on PCA-transformed data\n",
    "        model1 = LinearRegression()\n",
    "        lin_reg = model1.fit(X_pca, Y)\n",
    "\n",
    "        # Perform PCA transformation on out-of-sample data and predict\n",
    "        Xoos_pca = pca.transform(Weighted_X_oos)\n",
    "        Xoos_pca = np.array(Xoos_pca)\n",
    "        yhat = lin_reg.predict(Xoos_pca)\n",
    "\n",
    "        # Copy out-of-sample data and add predictions\n",
    "        inner_oos_data = in_oos_data.copy()\n",
    "        inner_oos_data['rethat'] = yhat\n",
    "\n",
    "        # Extract dates, true values, and predicted values\n",
    "        data_pca = inner_oos_data[['Dates', 'y', 'rethat']]\n",
    "        data_pca.columns = ['Dates', 'y', 'yhat']  # Rename columns\n",
    "        data_pca['model'] = 'sPCA'                  # Mark model type as PCA\n",
    "        data_pca['n'] = i                          # Mark number of principal components\n",
    "        ret_oos.append(data_pca)\n",
    "\n",
    "    # Find the optimal number of principal components (the one with the lowest mean squared error)\n",
    "    optimal_comp = prespecific_PCs[ret_test.index(max(ret_test))]\n",
    "    print(f\"The optimal PC number: {optimal_comp}\")\n",
    "\n",
    "    ## Training set: For estimating model parameters\n",
    "    # Refit PCA and linear regression models using the optimal number of principal components\n",
    "    pca_best = PCA(n_components=optimal_comp)\n",
    "    pca_best.fit(Weighted_X_train)\n",
    "    X_pca = pca_best.transform(Weighted_X_train)\n",
    "    Y = np.array(in_y_train)\n",
    "    X_pca = np.array(X_pca)\n",
    "    model1 = LinearRegression()\n",
    "    lin_reg = model1.fit(X_pca, Y)\n",
    "\n",
    "    ## Out-of-sample\n",
    "    # Perform prediction on out-of-sample data\n",
    "    Xoos_pca = pca_best.transform(Weighted_X_oos)\n",
    "    Xoos_pca = np.array(Xoos_pca)\n",
    "    yhat = lin_reg.predict(Xoos_pca)\n",
    "\n",
    "    # Copy out-of-sample data and add predictions\n",
    "    inner_oos_data = in_oos_data.copy()\n",
    "    inner_oos_data['rethat'] = yhat\n",
    "\n",
    "    # Extract dates, true values, and predicted values\n",
    "    data_pca = inner_oos_data[['Dates', 'y', 'rethat']]\n",
    "    data_pca.columns = ['Dates', 'y', 'yhat']\n",
    "\n",
    "    return pd.concat(ret_oos), data_pca, importance_dict, exp_ratio_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b6fef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vwretd</th>\n",
       "      <th>vwretx</th>\n",
       "      <th>ewretd</th>\n",
       "      <th>ewretx</th>\n",
       "      <th>totval</th>\n",
       "      <th>totcnt</th>\n",
       "      <th>usdval</th>\n",
       "      <th>usdcnt</th>\n",
       "      <th>spindx</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caldt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-02-28</th>\n",
       "      <td>0.021152</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.020327</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>11090951900.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10893939400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1203.6</td>\n",
       "      <td>0.018903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.01724</td>\n",
       "      <td>-0.018729</td>\n",
       "      <td>-0.012797</td>\n",
       "      <td>-0.014308</td>\n",
       "      <td>10900580800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>11092798500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1180.59</td>\n",
       "      <td>-0.019118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-29</th>\n",
       "      <td>-0.018926</td>\n",
       "      <td>-0.020076</td>\n",
       "      <td>-0.030961</td>\n",
       "      <td>-0.031763</td>\n",
       "      <td>10683198400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10900580800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1156.85</td>\n",
       "      <td>-0.020109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-31</th>\n",
       "      <td>0.031994</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>0.048563</td>\n",
       "      <td>0.047029</td>\n",
       "      <td>10972857600.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10683198400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1191.5</td>\n",
       "      <td>0.029952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.014499</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>10968272300.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10972857600.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1191.33</td>\n",
       "      <td>-0.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-30</th>\n",
       "      <td>-0.029207</td>\n",
       "      <td>-0.031638</td>\n",
       "      <td>-0.027829</td>\n",
       "      <td>-0.029855</td>\n",
       "      <td>14967939700.0</td>\n",
       "      <td>500</td>\n",
       "      <td>15481333300.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1632.97</td>\n",
       "      <td>-0.031298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>0.03166</td>\n",
       "      <td>0.030064</td>\n",
       "      <td>0.040402</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>15425476800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>14998800000.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1681.55</td>\n",
       "      <td>0.02975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-31</th>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.044953</td>\n",
       "      <td>0.042828</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>16084261800.0</td>\n",
       "      <td>500</td>\n",
       "      <td>15417335700.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1756.54</td>\n",
       "      <td>0.044596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-29</th>\n",
       "      <td>0.030817</td>\n",
       "      <td>0.028398</td>\n",
       "      <td>0.023739</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>16530422500.0</td>\n",
       "      <td>500</td>\n",
       "      <td>16089180200.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1805.81</td>\n",
       "      <td>0.02805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>0.02595</td>\n",
       "      <td>0.024196</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.02771</td>\n",
       "      <td>17040676100.0</td>\n",
       "      <td>500</td>\n",
       "      <td>16648053400.0</td>\n",
       "      <td>500</td>\n",
       "      <td>1848.36</td>\n",
       "      <td>0.023563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              vwretd    vwretx    ewretd    ewretx         totval  totcnt  \\\n",
       "caldt                                                                       \n",
       "2005-02-28  0.021152  0.019015  0.020327  0.018756  11090951900.0     500   \n",
       "2005-03-31  -0.01724 -0.018729 -0.012797 -0.014308  10900580800.0     500   \n",
       "2005-04-29 -0.018926 -0.020076 -0.030961 -0.031763  10683198400.0     500   \n",
       "2005-05-31  0.031994  0.030156  0.048563  0.047029  10972857600.0     500   \n",
       "2005-06-30  0.001717  0.000139  0.014499  0.013112  10968272300.0     500   \n",
       "...              ...       ...       ...       ...            ...     ...   \n",
       "2013-08-30 -0.029207 -0.031638 -0.027829 -0.029855  14967939700.0     500   \n",
       "2013-09-30   0.03166  0.030064  0.040402  0.038552  15425476800.0     500   \n",
       "2013-10-31  0.046268  0.044953  0.042828  0.041839  16084261800.0     500   \n",
       "2013-11-29  0.030817  0.028398  0.023739  0.021743  16530422500.0     500   \n",
       "2013-12-31   0.02595  0.024196  0.029739   0.02771  17040676100.0     500   \n",
       "\n",
       "                   usdval  usdcnt   spindx    sprtrn  \n",
       "caldt                                                 \n",
       "2005-02-28  10893939400.0     500   1203.6  0.018903  \n",
       "2005-03-31  11092798500.0     500  1180.59 -0.019118  \n",
       "2005-04-29  10900580800.0     500  1156.85 -0.020109  \n",
       "2005-05-31  10683198400.0     500   1191.5  0.029952  \n",
       "2005-06-30  10972857600.0     500  1191.33 -0.000143  \n",
       "...                   ...     ...      ...       ...  \n",
       "2013-08-30  15481333300.0     500  1632.97 -0.031298  \n",
       "2013-09-30  14998800000.0     500  1681.55   0.02975  \n",
       "2013-10-31  15417335700.0     500  1756.54  0.044596  \n",
       "2013-11-29  16089180200.0     500  1805.81   0.02805  \n",
       "2013-12-31  16648053400.0     500  1848.36  0.023563  \n",
       "\n",
       "[107 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### obtain S&P500 data\n",
    "sp500_df = db.raw_sql(\"\"\"select * \n",
    "                        from crsp_a_indexes.msp500\n",
    "                        where \n",
    "                        caldt >= '02/01/2005' and             \n",
    "                        caldt <= '12/31/2013'\n",
    "                    \"\"\", date_cols=['caldt'])    #  02/01/2005 & 12/31/2013 11/01/2004 & 12/31/2013  08/01/2004 & 12/31/2013\n",
    "\n",
    "sp500_df.set_index([\"caldt\"], drop=True, inplace=True)\n",
    "sp500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a01cd74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>D12</th>\n",
       "      <th>E12</th>\n",
       "      <th>b/m</th>\n",
       "      <th>tbl</th>\n",
       "      <th>AAA</th>\n",
       "      <th>BAA</th>\n",
       "      <th>lty</th>\n",
       "      <th>ntis</th>\n",
       "      <th>infl</th>\n",
       "      <th>ltr</th>\n",
       "      <th>corpr</th>\n",
       "      <th>svar</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-01</th>\n",
       "      <td>200501</td>\n",
       "      <td>19.7030</td>\n",
       "      <td>59.1067</td>\n",
       "      <td>0.278180</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-02-01</th>\n",
       "      <td>200502</td>\n",
       "      <td>19.9640</td>\n",
       "      <td>59.6633</td>\n",
       "      <td>0.271041</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>-0.0128</td>\n",
       "      <td>-0.0112</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>-0.021218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-01</th>\n",
       "      <td>200503</td>\n",
       "      <td>20.2250</td>\n",
       "      <td>60.2200</td>\n",
       "      <td>0.319857</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.009097</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.022209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-01</th>\n",
       "      <td>200504</td>\n",
       "      <td>20.4583</td>\n",
       "      <td>61.2333</td>\n",
       "      <td>0.329624</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.027552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-05-01</th>\n",
       "      <td>200505</td>\n",
       "      <td>20.6917</td>\n",
       "      <td>62.2467</td>\n",
       "      <td>0.320966</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>-0.002443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>201307</td>\n",
       "      <td>33.6455</td>\n",
       "      <td>92.0900</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-0.0173</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.031298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>201308</td>\n",
       "      <td>34.0247</td>\n",
       "      <td>93.2300</td>\n",
       "      <td>0.340713</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.02975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-01</th>\n",
       "      <td>201309</td>\n",
       "      <td>34.4039</td>\n",
       "      <td>94.3700</td>\n",
       "      <td>0.333521</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.044596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>201310</td>\n",
       "      <td>34.6000</td>\n",
       "      <td>96.3133</td>\n",
       "      <td>0.324595</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.009623</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.02805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-01</th>\n",
       "      <td>201311</td>\n",
       "      <td>34.7960</td>\n",
       "      <td>98.2567</td>\n",
       "      <td>0.313685</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>-0.0236</td>\n",
       "      <td>-0.0086</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.023563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dates      D12      E12       b/m     tbl     AAA     BAA  \\\n",
       "Dates                                                                    \n",
       "2005-01-01  200501  19.7030  59.1067  0.278180  0.0233  0.0536  0.0602   \n",
       "2005-02-01  200502  19.9640  59.6633  0.271041  0.0254  0.0520  0.0582   \n",
       "2005-03-01  200503  20.2250  60.2200  0.319857  0.0274  0.0540  0.0606   \n",
       "2005-04-01  200504  20.4583  61.2333  0.329624  0.0278  0.0533  0.0605   \n",
       "2005-05-01  200505  20.6917  62.2467  0.320966  0.0284  0.0515  0.0601   \n",
       "...            ...      ...      ...       ...     ...     ...     ...   \n",
       "2013-07-01  201307  33.6455  92.0900  0.325563  0.0004  0.0434  0.0532   \n",
       "2013-08-01  201308  34.0247  93.2300  0.340713  0.0004  0.0454  0.0542   \n",
       "2013-09-01  201309  34.4039  94.3700  0.333521  0.0002  0.0464  0.0547   \n",
       "2013-10-01  201310  34.6000  96.3133  0.324595  0.0005  0.0453  0.0531   \n",
       "2013-11-01  201311  34.7960  98.2567  0.313685  0.0007  0.0463  0.0538   \n",
       "\n",
       "               lty      ntis      infl     ltr   corpr      svar         y  \n",
       "Dates                                                                       \n",
       "2005-01-01  0.0465  0.013545  0.002102  0.0300  0.0277  0.000821  0.017303  \n",
       "2005-02-01  0.0479  0.011758  0.005768 -0.0128 -0.0112  0.000834 -0.021218  \n",
       "2005-03-01  0.0488  0.009097  0.007821 -0.0072 -0.0125  0.000860 -0.022209  \n",
       "2005-04-01  0.0461  0.007936  0.006725  0.0373  0.0327  0.001826  0.027552  \n",
       "2005-05-01  0.0440  0.004777 -0.001028  0.0297  0.0295  0.000859 -0.002443  \n",
       "...            ...       ...       ...     ...     ...       ...       ...  \n",
       "2013-07-01  0.0344  0.008361  0.000394 -0.0173  0.0031  0.000502 -0.031298  \n",
       "2013-08-01  0.0351  0.010332  0.001203 -0.0079 -0.0074  0.000950   0.02975  \n",
       "2013-09-01  0.0349  0.010119  0.001163  0.0061  0.0014  0.000622  0.044596  \n",
       "2013-10-01  0.0342  0.009623 -0.002575  0.0128  0.0211  0.001438   0.02805  \n",
       "2013-11-01  0.0361  0.010325 -0.002042 -0.0236 -0.0086  0.000644  0.023563  \n",
       "\n",
       "[107 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macroeconomic predictors (from Amit Goyal homepage)\n",
    "# Variables:\n",
    "#   D12: Dividends are 12-month moving sums of dividends paid on the S&P 500 index.\n",
    "#   E12: Earnings are 12-month moving sums of earnings on the S&P500 index.\n",
    "#   B/M: Book-to-market ratio\n",
    "#   TBL: T-Bill rates (U.S. Yields On Short-Term United States Securities,)\n",
    "#   AAA(BAA): Corporate Bond Yields on AAA(BAA)-related bonds\n",
    "#   Lty: long-term government bond yield\n",
    "#   Ntis: Net issuing activity.\n",
    "#   infl: inflation\n",
    "#   SVAR: Stock Variance is computed as sum of squared daily returns on the S&P 500.\n",
    "predictors = pd.read_csv(os.path.join('data', 'l5', \"PredictorData2024.csv\"), index_col=0).iloc[:-2,:]\n",
    "predictors.loc[:,'Dates'] = predictors.index.astype(int).astype(str).values\n",
    "predictors.set_index(pd.to_datetime(predictors.loc[:,'Dates'], format=\"%Y%m\"), inplace = True)\n",
    "reg_df = predictors.loc[\"2005-01-01\":\"2013-11-01\", ['Dates', 'D12','E12','b/m','tbl','AAA','BAA','lty','ntis','infl','ltr','corpr','svar']].copy(deep=True)\n",
    "reg_df.loc[:,'y'] = sp500_df.loc[:,'sprtrn'].values - predictors.loc[\"2005-02-01\":\"2013-12-01\",'Rfree'].values\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "767290aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201101', '201102', '201103']\n",
      "The optimal PC number: 2\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201104', '201105', '201106']\n",
      "The optimal PC number: 5\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201107', '201108', '201109']\n",
      "The optimal PC number: 3\n",
      "The optimal PC number: 2\n",
      "\n",
      "\n",
      "['201110', '201111', '201112']\n",
      "The optimal PC number: 6\n",
      "The optimal PC number: 5\n",
      "\n",
      "\n",
      "['201201', '201202', '201203']\n",
      "The optimal PC number: 6\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201204', '201205', '201206']\n",
      "The optimal PC number: 6\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201207', '201208', '201209']\n",
      "The optimal PC number: 6\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201210', '201211', '201212']\n",
      "The optimal PC number: 6\n",
      "The optimal PC number: 3\n",
      "\n",
      "\n",
      "['201301', '201302', '201303']\n",
      "The optimal PC number: 1\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201304', '201305', '201306']\n",
      "The optimal PC number: 2\n",
      "The optimal PC number: 1\n",
      "\n",
      "\n",
      "['201307', '201308', '201309']\n",
      "The optimal PC number: 1\n",
      "The optimal PC number: 6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## OOS evaluation with a rolling window approach\n",
    "Xtodrop = ['Dates','y']\n",
    "all_month_list = list(reg_df['Dates'].values)\n",
    "train_month_n = 60\n",
    "test_month_n = 12\n",
    "oos_month_n = 3\n",
    "Frist_flag = True\n",
    "prev_i = 0\n",
    "\n",
    "for i, d in enumerate(all_month_list):\n",
    "    if i < train_month_n + test_month_n + oos_month_n:\n",
    "        continue\n",
    "    else:\n",
    "        if i - prev_i < oos_month_n:\n",
    "            continue\n",
    "            \n",
    "        ## Split the dataset into training, test, and out-of-sample sets\n",
    "        # train_data is used to train the model and estimate model parameters\n",
    "        # test_data is used to find the optimal hyperparameters\n",
    "        # oos_data is used to evaluate the model's out-of-sample predictive performance\n",
    "        train_monthes = all_month_list[i - oos_month_n - test_month_n - train_month_n: i - oos_month_n - test_month_n]\n",
    "        test_monthes = all_month_list[i - oos_month_n - test_month_n : i - oos_month_n]\n",
    "        oos_month = all_month_list[i - oos_month_n : i]\n",
    "        print(oos_month)\n",
    "        prev_i = i\n",
    "        \n",
    "        train_data = reg_df[reg_df['Dates'].apply(lambda x: True if x in train_monthes else False)]\n",
    "        test_data = reg_df[reg_df['Dates'].apply(lambda x: True if x in test_monthes else False)]\n",
    "        oos_data = reg_df[reg_df['Dates'].apply(lambda x: True if x in oos_month else False)]\n",
    "        \n",
    "        X_train = train_data.drop(columns = Xtodrop)\n",
    "        y_train = train_data['y']\n",
    "        \n",
    "        X_test = test_data.drop(columns = Xtodrop)\n",
    "        y_test = test_data['y']\n",
    "        \n",
    "        X_oos = oos_data.drop(columns = Xtodrop)\n",
    "        y_oos = oos_data['y']\n",
    "        \n",
    "        ## Data standardization\n",
    "        to_Norm = pd.concat([train_data, test_data, oos_data])\n",
    "        normed_data = Norm(to_Norm, Xtodrop)\n",
    "        train_data_normed = normed_data[normed_data['Dates'].apply(lambda x: True if x in train_monthes else False)]\n",
    "        test_data_normed = normed_data[normed_data['Dates'].apply(lambda x: True if x in test_monthes else False)]\n",
    "        oos_data_normed = normed_data[normed_data['Dates'].apply(lambda x: True if x in oos_month else False)]\n",
    "        \n",
    "        X_train_normed = train_data_normed.drop(columns = Xtodrop)\n",
    "        y_train = train_data['y']\n",
    "        \n",
    "        X_test_normed = test_data_normed.drop(columns = Xtodrop)\n",
    "        y_test = test_data['y']\n",
    "        \n",
    "        X_oos_normed = oos_data_normed.drop(columns = Xtodrop)\n",
    "        y_oos = oos_data['y']\n",
    "        \n",
    "        ## Model training and prediction\n",
    "        y_mean = np.mean(y_train.to_list() + y_test.to_list())\n",
    "        history_avg = ([y_mean for i in range(oos_month_n)])\n",
    "        pca_result = PCA_method(X_train_normed, y_train, X_test_normed, y_test, X_oos_normed, test_data_normed, oos_data_normed)[1]\n",
    "        pls_result = PLS_method(X_train_normed, y_train, X_test_normed, y_test, X_oos_normed, test_data_normed, oos_data_normed)[1]\n",
    "        spca_result = sPCA_method(X_train_normed, y_train, X_test_normed, y_test, X_oos_normed, test_data_normed, oos_data_normed)[1]\n",
    "        \n",
    "        models_pred = pca_result.copy()\n",
    "        models_pred.columns = ['Dates','y','ypca']\n",
    "        models_pred.loc[:,'ypls'] = pls_result.yhat.values\n",
    "        models_pred.loc[:,'yspca'] = spca_result.yhat.values\n",
    "        models_pred.loc[:,'ybar'] = history_avg\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "        ## Save the model's prediction results for each period\n",
    "        if Frist_flag:\n",
    "            Models_pred = models_pred.copy()\n",
    "            Frist_flag = False\n",
    "        else:\n",
    "            Models_pred = pd.concat([Models_pred, models_pred], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcae0ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>y</th>\n",
       "      <th>ypca</th>\n",
       "      <th>ypls</th>\n",
       "      <th>yspca</th>\n",
       "      <th>ybar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>201101</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.018807</td>\n",
       "      <td>0.015607</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>201102</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>0.016456</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-01</th>\n",
       "      <td>201103</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>0.016723</td>\n",
       "      <td>0.016135</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-01</th>\n",
       "      <td>201104</td>\n",
       "      <td>-0.013501</td>\n",
       "      <td>-0.004027</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-01</th>\n",
       "      <td>201105</td>\n",
       "      <td>-0.018258</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-01</th>\n",
       "      <td>201106</td>\n",
       "      <td>-0.021474</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>0.014202</td>\n",
       "      <td>0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01</th>\n",
       "      <td>201107</td>\n",
       "      <td>-0.056891</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>0.015959</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-08-01</th>\n",
       "      <td>201108</td>\n",
       "      <td>-0.071762</td>\n",
       "      <td>0.017029</td>\n",
       "      <td>-0.035177</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01</th>\n",
       "      <td>201109</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>0.017655</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>201110</td>\n",
       "      <td>-0.005059</td>\n",
       "      <td>-0.010513</td>\n",
       "      <td>-0.035656</td>\n",
       "      <td>-0.033303</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-11-01</th>\n",
       "      <td>201111</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.034540</td>\n",
       "      <td>-0.055629</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>201112</td>\n",
       "      <td>0.043583</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>201201</td>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.022218</td>\n",
       "      <td>0.019019</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-01</th>\n",
       "      <td>201202</td>\n",
       "      <td>0.031332</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>201203</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>-0.006996</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>201204</td>\n",
       "      <td>-0.062751</td>\n",
       "      <td>0.030287</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>0.009611</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-05-01</th>\n",
       "      <td>201205</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.042068</td>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-01</th>\n",
       "      <td>201206</td>\n",
       "      <td>0.012598</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>-0.013456</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td>201207</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.021349</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-01</th>\n",
       "      <td>201208</td>\n",
       "      <td>0.024136</td>\n",
       "      <td>0.019077</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-01</th>\n",
       "      <td>201209</td>\n",
       "      <td>-0.019889</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>-0.003075</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>201210</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-01</th>\n",
       "      <td>201211</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-01</th>\n",
       "      <td>201212</td>\n",
       "      <td>0.050428</td>\n",
       "      <td>-0.003262</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>201301</td>\n",
       "      <td>0.011061</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-01</th>\n",
       "      <td>201302</td>\n",
       "      <td>0.035988</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>-0.003778</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>201303</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>201304</td>\n",
       "      <td>0.020763</td>\n",
       "      <td>0.011295</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>201305</td>\n",
       "      <td>-0.014999</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.001271</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-01</th>\n",
       "      <td>201306</td>\n",
       "      <td>0.049462</td>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>201307</td>\n",
       "      <td>-0.031298</td>\n",
       "      <td>0.010728</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.002897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-01</th>\n",
       "      <td>201308</td>\n",
       "      <td>0.02975</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.002897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-01</th>\n",
       "      <td>201309</td>\n",
       "      <td>0.044596</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.002897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dates         y      ypca      ypls     yspca      ybar\n",
       "Dates                                                               \n",
       "2011-01-01  201101  0.031857  0.018807  0.015607  0.008822  0.000418\n",
       "2011-02-01  201102 -0.001147  0.016456  0.015961  0.007699  0.000418\n",
       "2011-03-01  201103  0.028495  0.016723  0.016135  0.007065  0.000418\n",
       "2011-04-01  201104 -0.013501 -0.004027  0.020992  0.015183  0.001603\n",
       "2011-05-01  201105 -0.018258  0.001186  0.021956  0.014712  0.001603\n",
       "2011-06-01  201106 -0.021474 -0.016075  0.016126  0.014202  0.001603\n",
       "2011-07-01  201107 -0.056891  0.014732  0.020416  0.015959  0.000049\n",
       "2011-08-01  201108 -0.071762  0.017029 -0.035177  0.015254  0.000049\n",
       "2011-09-01  201109  0.107723  0.020174  0.017655  0.022322  0.000049\n",
       "2011-10-01  201110 -0.005059 -0.010513 -0.035656 -0.033303  0.000183\n",
       "2011-11-01  201111  0.008533 -0.011126 -0.034540 -0.055629  0.000183\n",
       "2011-12-01  201112  0.043583  0.007381  0.001323 -0.018066  0.000183\n",
       "2012-01-01  201201  0.040589  0.022218  0.019019  0.011966  0.000144\n",
       "2012-02-01  201202  0.031332  0.012375  0.002339  0.009698  0.000144\n",
       "2012-03-01  201203 -0.007498  0.006724 -0.006996  0.007864  0.000144\n",
       "2012-04-01  201204 -0.062751  0.030287 -0.001474  0.009611  0.000858\n",
       "2012-05-01  201205  0.039555  0.042068  0.010785  0.011435  0.000858\n",
       "2012-06-01  201206  0.012598  0.021745 -0.013456  0.008704  0.000858\n",
       "2012-07-01  201207  0.019663  0.021349  0.001951  0.004883  0.001239\n",
       "2012-08-01  201208  0.024136  0.019077 -0.000471  0.002678  0.001239\n",
       "2012-09-01  201209 -0.019889  0.010840 -0.003075  0.000604  0.001239\n",
       "2012-10-01  201210  0.002747  0.010033  0.003293  0.005258  0.000669\n",
       "2012-11-01  201211  0.006968  0.000039  0.001097  0.002999  0.000669\n",
       "2012-12-01  201212  0.050428 -0.003262 -0.000836 -0.000172  0.000669\n",
       "2013-01-01  201301  0.011061  0.005061  0.000825 -0.002771  0.001080\n",
       "2013-02-01  201302  0.035988  0.004268  0.002782 -0.003778  0.001080\n",
       "2013-03-01  201303  0.018086  0.005522  0.002448 -0.002269  0.001080\n",
       "2013-04-01  201304  0.020763  0.011295  0.010156  0.006024  0.001722\n",
       "2013-05-01  201305 -0.014999  0.007545  0.002917 -0.001271  0.001722\n",
       "2013-06-01  201306  0.049462  0.005963  0.001646 -0.004113  0.001722\n",
       "2013-07-01  201307 -0.031298  0.010728  0.001780  0.003586  0.002897\n",
       "2013-08-01  201308   0.02975  0.010361  0.002153  0.008457  0.002897\n",
       "2013-09-01  201309  0.044596  0.009637  0.000971  0.008882  0.002897"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0acb2baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ PCA ============\n",
      "OLS R2_OOS(%): 2.36\n",
      "DM Statistics: (np.float64(0.1407520383331753), np.float64(0.4440329168086795))\n",
      "CW Statistics: (np.float64(0.9189), np.float64(0.17907393996876697))\n",
      "============ PLS ============\n",
      "OLS R2_OOS(%): 4.3\n",
      "DM Statistics: (np.float64(0.28673982314907714), np.float64(0.3871557714443564))\n",
      "CW Statistics: (np.float64(1.6663), np.float64(0.04782683837028223))\n",
      "============ SPCA ============\n",
      "OLS R2_OOS(%): -16.69\n",
      "DM Statistics: (np.float64(-1.0216591564624786), np.float64(0.8465288757291531))\n",
      "CW Statistics: (np.float64(2.4018), np.float64(0.008157312736450817))\n"
     ]
    }
   ],
   "source": [
    "## Model evaluation\n",
    "for model in ['pca','pls','spca']:\n",
    "    ymodel = f\"y{model}\"\n",
    "    R2_OOS_ols = calculate_R_OOS_2(Models_pred['ybar'], Models_pred['y'], Models_pred[ymodel])\n",
    "    DM = calculate_DM_statistic(Models_pred['ybar'] - Models_pred['y'], Models_pred[ymodel] - Models_pred['y'], alpha=0.05)\n",
    "    Models_pred_copy = Models_pred.loc[:,['y','ybar',ymodel]]\n",
    "    Models_pred_copy.columns = ['r_real', 'r_bar', 'r_hat']\n",
    "    CW = calculate_CW_statistic(Models_pred_copy)\n",
    "    \n",
    "    print(\"=\"*12 + f\" {model.upper()} \" + \"=\"*12)\n",
    "    print(f\"OLS R2_OOS(%): {R2_OOS_ols}\")   # Generally, an R2_OOS greater than 2% is considered economically significant. \n",
    "                                            # However, since returns inherently contain a lot of unpredictable information, \n",
    "                                            # under different model specifications it is difficult for any model to consistently \n",
    "                                            # outperform the historical average. In such cases, R2_OOS can be less than 0. \n",
    "                                            # For further discussion, see: Campbell, J. Y., & Thompson, S. B. (2008). \n",
    "                                            # Predicting excess stock returns out of sample: Can anything beat the historical average?. \n",
    "                                            # The Review of Financial Studies, 21(4), 1509-1531.\n",
    "\n",
    "    print(f\"DM Statistics: {DM}\")           # The first element of the output is the test statistic, followed by the p-value (same below). \n",
    "                                            # A positive DM statistic means the model’s forecast error is smaller than that of the historical average.\n",
    "\n",
    "    print(f\"CW Statistics: {CW}\")           # Similarly, a positive CW statistic indicates that the adjusted forecast error of the historical average \n",
    "                                            # is significantly larger than that of the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finnlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
